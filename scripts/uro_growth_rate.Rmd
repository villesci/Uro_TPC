---
title: "Urosalpinx growth rate (length)"
author: "Andrew Villeneuve"
date: "5/26/2020"
output:
  word_document: default
  html_document: default
  pdf_document: default
---


# The Study - read first 

For this part of the study, we measured growth rates of juvenile Urosalpinx snails. We measured snail length using ImageJ within two days of hatching, and grew them in tea strainers separated by population for 24 days in a common garden experiment. Nine replicates per population were distributed in six temperatures, with three groups of three subreplicates in each temperature/population treatment. Snails were given food ad libitum. The end length was recorded using digital calipers after 24 days, and we subtracted the starting length from the beginning length to get the growth rate (over 24 days; see data exploration for reasoning). From this growth data, we can create thermal performance curves (TPCs) for each population to show the growth response of Urosaplinx populations to a range of laboratory temperatures.

The analysis of these growth curves requires two steps: 

1) the creation of models that describe the curved TPC shape using segmented and quadratic models and

2) the extraction of breakpoints (thermal optima = x breakpoint, maximal trait performance = y optima) for each population's TPC and modeling which environmental factors best describe any patterns in these optima across populations. I do this across two methods - segmented and quadratic regression. We want to see if both methods give approximately the same results, and based on model outputs decide which method we should use.

These two steps are presented, separately, in the Data Analysis section. The organization of these analyses thusly:

* Broken stick regression - I create, analyze, and plot segmented regressions 
  * Breakpoint analysis, broken stick - I extract the thermal optima (x brkpt) and maximal trait performance (y brkpt) of each population's segmented regression

* Quadratic model - I create, analyze, and plot quadratic regressions. 
  * Breakpoint analysis, quadratic - I extract the thermal optima (x brkpt) and maximal trait performance (y brkpt) of each population's quadratic regression
  

# Metadata

* code

  * Unique code for each indiviudal snail, corresponding to population, temperature treatment. First digit = temperature (1=16,2=20,3=24,4=26, 5=28, 6=30), second digit =  site (1=Willapa, 2=Humboldt, 3=Great Bay, 4=Woods Hole, 5=Oyster, 6=Beaufort, 7=Folly Beach, 8=Skidaway), third digit = tupperware bin number (1-3), fourth digit = snail replicate (1-3)

* pop

  * Source population of each snail. See data table below for list of site abbreivations with site. 

* temp

  * Common garden temperature the snails were raised in for 24 days. Degrees C

* hatch

  * hatch date of each snail from it's egg case (m/dd/yyyy)

* exp.date

  * Date on which hatchling snails were placed in the common garden experiment. Not more then 2 days from the hatch date. (m/dd/yyyy)

* grow.date

  * End date where growth measurements were taken. 24 days after exp.date, therefore no more then 26 days post hatch (m/dd/yyyy)

* alive

  * Tracks if snails survived the experient. m marks missing, n marks no, y marks yes

* rem.oysters

  * Was there a surplus of food at the end of the experiment? n marks no, y marks yes

* cal.length.start

  * caliper length of hatchlings upon entering the experment. We took photos of snails before entering snails into the experiment, and then used ImageJ to extract snail sizes. Size in mm

* cal.length.end

  * caliper length of hatchling at the end of the experiemnt. We took caliper measurements of the snails, as well as verifying the measurements using a subset of photographs in ImageJ. Size in mm

* wt

  * End weight of snail. Note that no initial starting weight was recorded. Weight in g.

* ran.out

  * Did the snail ever run out of food during the consumption experiment? 1 for yes, 0 for no

* bin

  * Bin number, controls subreplication. The third digit of the code. 

* oce

  * Ocean (Atlantic or Pacific)

```{r,echo=F, warning=F}
data.frame("site abbreviation" = c("gbj","wh","oy","bf","fb","gcsk","nah1516","hmi2"), "site"=c("Great Bay, NH","Woods Hole, MA","Oyster, VA","Beaufort, NC","Folly Beach, SC","Skidaway, GA","Willapa, WA","Humboldt, CA"))


```

# Data Setup


```{r setup, include=FALSE,echo=F}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(rmarkdown)
library(dplyr)
library(ggplot2)
library(forcats)
library(PerformanceAnalytics)
library(sjPlot)
library(lubridate)
library(HH)
library(AICcmodavg)
library(MuMIn)
library(segmented)
library(ggiraphExtra)
library(extrafont)
library(here)
library(lubridate)
library(plyr)
library(tidyr)
library(digest)
library(ggnewscale)
loadfonts(device = "win")


growth<-read.csv(here::here("data/growth.csv"))
summary(growth)
#identify and edit errors that are most certainly due to neglecting a 0 in data entry.

which(growth$wt>0.09)
growth[92,12]=0.0109
growth[193,12]=.0151
growth[232,12]=.023
growth[268,12]=.0261

#Let's bring in the consumption data, and see which snails ran out of food MORE than once. We will keep snails that ran out only once. 

cons<-read.csv(here::here("data/uro.consumption2.csv"))
cons<-na.omit(cons)

cons$allcons<-ifelse(cons$all.consumed=="n","0",ifelse(cons$all.consumed=="y","1",NA))
cons$allcons<-as.numeric(cons$allcons)

consfilter<-cons%>%filter(all.consumed!="n")%>%group_by(TPC.Label)%>%dplyr::summarise(n=n())
consfilter$TPC.Label<-as.character(consfilter$TPC.Label)


#when did snails die, timepoint wise?
conscase<-cons%>%filter(all.consumed!="n")%>%group_by(timepoint)%>%dplyr::summarise(n=n())
conscase$n<-as.integer(conscase$n)


#only 6212 ran out twice. Below we remove it. If we wanted to do all the snails that ran out, we would run the next line
growth.alive<-subset(growth,code!=(6212))
##this below not only eliminates snails who ran out of food, but also
###eliminate snails that ever ran out of food
##step beyod simply removing measurements when snails ran out of food. 
#growth.alive<-subset(growth,code!=(6833)&code!=(6831)&code!=(6711)&code!=(6632)&code!=(6631)&code!=(6611)&code!=(6433)&code!=(6422)&code!=(6412)&code!=(6411)&code!=(6233)&code!=(6212)&code!=(6212)&code!=(6111)&code!=(5831)&code!=(5813)&code!=(5732)&code!=(5731)&code!=(5723)&code!=(5711)&code!=(5622)&code!=(5531)&code!=(5333)&code!=(5313)&code!=(5312)&code!=(5213)&code!=(5121)&code!=(5112)&code!=(4522)&code!=(4521)&code!=(4433)&code!=(4432)&code!=(4231)&code!=(3821)&code!=(3712)&code!=(3433)&code!=(3432)&code!=(3421)&code!=(3413)&code!=(2422)&code!=(2421)&code!=(6832))

#how many died? 37
dead<-growth.alive%>%filter(alive=="n")%>%group_by(temp)%>%dplyr::summarise(n=n())

deadpop<-growth.alive%>%filter(alive=="n")%>%group_by(pop)%>%dplyr::summarise(n=n())

#how many disappeared/unknown?
dis<-growth.alive%>%filter(alive=="m")%>%dplyr::summarise(n=n())



##eliminate all snails that died/unknown. "n" = died, "m' = unknown (escaped, crushed, etc. ) 
growth.alive<-growth.alive[!(growth.alive$alive=="n"),]
growth.alive<-growth.alive[!(growth.alive$alive=="m"),]
growth.alive<-tidyr::drop_na(growth.alive)


##temperature data


gbj<-read.csv(here::here("data/environmental_data/rawAtlantic/atl/gbj.csv"),header=T)
gbj$rdate<-as.POSIXct(gbj$DateTimeStamp,tz="","%m/%d/%Y%H:%M")
gbj$oce<-"a"
wh<-read.csv(here::here("data/environmental_data/rawAtlantic/atl/wh.csv"),header=T)
wh$rdate<-as.POSIXct(wh$DateTimeStamp,tz="", "%m/%d/%Y%H:%M")
wh$oce<-"a"
oy<-read.csv(here::here("data/environmental_data/rawAtlantic/atl/oy.csv"),header=T)
oy$rdate<-as.POSIXct(oy$DateTimeStamp,tz="", "%m/%d/%Y%H:%M")
oy$oce<-"a"
bf<-read.csv(here::here("data/environmental_data/rawAtlantic/atl/bf.csv"),header=T)
bf$rdate<-as.POSIXct(bf$DateTimeStamp,tz="", "%m/%d/%Y%H:%M")
bf$oce<-"a"
fb<-read.csv(here::here("data/environmental_data/rawAtlantic/atl/fb.csv"),header=T)
fb$rdate<-as.POSIXct(fb$DateTimeStamp,tz="", "%m/%d/%Y%H:%M")
fb$oce<-"a"
gcsk<-read.csv(here::here("data/environmental_data/rawAtlantic/atl/gcsk.csv"),header=T)
gcsk$rdate<-as.POSIXct(gcsk$DateTimeStamp,tz="", "%m/%d/%Y%H:%M")
gcsk$oce<-"a"

nah1516<-read.csv(here::here("data/environmental_data/rawPacific/pac/nahcotta_2015_2016.csv"),header=T)#2015 through August, 2016 data after that
nah1516$rdate<-as.POSIXct(nah1516$DateTimeStamp,tz="", "%m/%d/%Y%H:%M")
nah1516$oce<-"p"
hmi2<-read.csv(here::here("data/environmental_data/rawPacific/pac/hmi2.csv"),header=T)
hmi2$rdate<-as.POSIXct(hmi2$DateTimeStamp,tz="", "%m/%d/%Y%H:%M")#Indian island 2015
hmi2$oce<-"p"
to3<-read.csv(here::here("data/environmental_data/rawPacific/pac/to3.csv"),header=T)
to3$rdate<-as.POSIXct(to3$DateTimeStamp,tz="","%m/%d/%Y%H:%M")##stitched 2014 and 2015 (post Nove. 21 data together)
to3$oce<-"p"

#create objects of tempreatures during summer only 
s.gbj<-filter(gbj,rdate>"2018-06-01 00:00:00" & rdate< "2018-09-30 00:00:00")
s.wh<-filter(wh,rdate>"2018-06-01 00:00:00" & rdate< "2018-09-30 00:00:00")
s.oy<-filter(oy,rdate>"2018-06-01 00:00:00" & rdate< "2018-09-30 00:00:00")
s.bf<-filter(bf,rdate>"2018-06-01 00:00:00" & rdate< "2018-09-30 00:00:00")
s.fb<-filter(fb,rdate>"2018-06-01 00:00:00" & rdate< "2018-09-30 00:00:00")
s.to3<-filter(to3,rdate>"2018-06-01 00:00:00" & rdate< "2018-09-30 00:00:00")
s.hmi2<-filter(hmi2,rdate>"2018-06-01 00:00:00" & rdate< "2018-09-30 00:00:00")
s.nah1516<-filter(nah1516,rdate>"2018-06-01 00:00:00" & rdate< "2018-09-30 00:00:00")
s.gcsk<-filter(gcsk,rdate>"2018-06-01 00:00:00" & rdate< "2018-09-30 00:00:00")

##Quartiles
q<-data.frame("site" = c("gbj","wh","oy","bf","fb","nah1516","hmi2","to3","gcsk"),"quantile"=NA,"decile"=NA, "max"=NA, "mean"=NA,"summer mean"=NA,"seasonlength10"=NA,"seasonlength12"=NA)
q[1,2]<-quantile(s.gbj$WTMP,0.75,type=1)
q[2,2]<-quantile(s.wh$WTMP,0.75,type=1)
q[3,2]<-quantile(s.oy$WTMP,0.75,type=1)
q[4,2]<-quantile(s.bf$WTMP,0.75,type=1)
q[5,2]<-quantile(s.fb$WTMP,0.75,type=1)
q[6,2]<-quantile(s.nah1516$WTMP,0.75,type=1)
q[7,2]<-quantile(s.hmi2$WTMP,0.75,type=1)
q[8,2]<-quantile(s.to3$WTMP,0.75,type=1)
q[9,2]<-quantile(s.gcsk$WTMP,0.75,type=1)

#upper 90th
q[1,3]<-quantile(s.gbj$WTMP,0.9,type=1)
q[2,3]<-quantile(s.wh$WTMP,0.9,type=1)
q[3,3]<-quantile(s.oy$WTMP,0.9,type=1)
q[4,3]<-quantile(s.bf$WTMP,0.9,type=1)
q[5,3]<-quantile(s.fb$WTMP,0.9,type=1)
q[6,3]<-quantile(s.nah1516$WTMP,0.9,type=1)
q[7,3]<-quantile(s.hmi2$WTMP,0.9,type=1)
q[8,3]<-quantile(s.to3$WTMP,0.9,type=1)
q[9,3]<-quantile(s.gcsk$WTMP,0.9,type=1)

#maximum temperature
q[1,4]<-s.gbj %>%  summarise(Value = max(WTMP))
q[2,4]<-s.wh  %>% summarise(Value = max(WTMP))
q[3,4]<-s.oy  %>% summarise(Value = max(WTMP))
q[4,4]<-s.bf  %>% summarise(Value = max(WTMP))
q[5,4]<-s.fb  %>% summarise(Value = max(WTMP))
q[6,4]<-s.nah1516 %>% summarise(Value = max(WTMP))
q[7,4]<-s.hmi2  %>% summarise(Value = max(WTMP))
q[8,4]<-s.to3  %>% summarise(Value = max(WTMP))
q[9,4]<-s.gcsk  %>% summarise(Value=max(WTMP))

#means
q[1,5]<-mean(gbj$WTMP)
q[2,5]<-mean(wh$WTMP)
q[3,5]<-mean(oy$WTMP)
q[4,5]<-mean(bf$WTMP)
q[5,5]<-mean(fb$WTMP)
q[6,5]<-mean(nah1516$WTMP)
q[7,5]<-mean(hmi2$WTMP)
q[8,5]<-mean(to3$WTMP)
q[9,5]<-mean(gcsk$WTMP)

#summer means
#means
q[1,6]<-mean(s.gbj$WTMP)
q[2,6]<-mean(s.wh$WTMP)
q[3,6]<-mean(s.oy$WTMP)
q[4,6]<-mean(s.bf$WTMP)
q[5,6]<-mean(s.fb$WTMP)
q[6,6]<-mean(s.nah1516$WTMP)
q[7,6]<-mean(s.hmi2$WTMP)
q[8,6]<-mean(s.to3$WTMP)
q[9,6]<-mean(s.gcsk$WTMP)

#season length

q[1,8]<-gbj%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>12.5)%>%tally
q[2,8]<-wh%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>12.5)%>%tally
q[3,8]<-oy%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>12.5)%>%tally
q[4,8]<-bf%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>12.5)%>%tally
q[5,8]<-fb%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>12.5)%>%tally
q[6,8]<-nah1516%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>12.5)%>%tally
q[7,8]<-hmi2%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>12.5)%>%tally
q[8,8]<-to3%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>12.5)%>%tally
q[9,8]<-gcsk%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>12.5)%>%tally

q[1,7]<-gbj%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>10)%>%tally
q[2,7]<-wh%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>10)%>%tally
q[3,7]<-oy%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>10)%>%tally
q[4,7]<-bf%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>10)%>%tally
q[5,7]<-fb%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>10)%>%tally
q[6,7]<-nah1516%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>10)%>%tally
q[7,7]<-hmi2%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>10)%>%tally
q[8,7]<-to3%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>10)%>%tally
q[9,7]<-gcsk%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>10)%>%tally


pac2<-rbind(hmi2,nah1516)
atll<-rbind(gcsk,fb,bf,oy,wh,gbj)

temp<-rbind(pac2,atll) #temperature data for all

means<-data.frame(with(temp,tapply(WTMP,site,mean)))

#summer means

summer.temp<-filter(temp,rdate>"2018-06-01 00:00:00" & rdate< "2018-09-30 00:00:00")
s.mean<-data.frame(with(summer.temp,tapply(WTMP,site,mean)))

temp$date<-as.Date(temp$rdate)

temp$site<-factor(temp$site, levels=c("gbj","wh","oy","bf","fb","GCSK","nah15","hmi2"))
#"Great Bay, NH","Woods Hole, MA","Oyster, VA","Beaufort, NC","Folly Beach, SC","Skidaway, GA","Willapa, WA","Humboldt, CA"

#egg lay dates
#egg laying mean
lay_sk<-mean((filter(gcsk,rdate>"2018-03-01 00:00:00" & rdate< "2018-03-30 00:00:00"))$WTMP)
lay_fb<-mean((filter(fb,rdate>"2018-03-01 00:00:00" & rdate< "2018-03-30 00:00:00"))$WTMP)
lay_bf<-mean((filter(bf,rdate>"2018-03-15 00:00:00" & rdate< "2018-04-15 00:00:00"))$WTMP)
lay_oy<-mean((filter(oy,rdate>"2018-05-01 00:00:00" & rdate< "2018-05-30 00:00:00"))$WTMP)
lay_wh<-mean((filter(wh,rdate>"2018-05-15 00:00:00" & rdate< "2018-06-15 00:00:00"))$WTMP)
lay_gb<-mean((filter(gbj,rdate>"2018-06-01 00:00:00" & rdate< "2018-06-30 00:00:00"))$WTMP)
lay_hm<-mean((filter(hmi2,rdate>"2018-04-15 00:00:00" & rdate< "2018-05-15 00:00:00"))$WTMP)#inat
lay_wp<-mean((filter(nah1516,rdate>"2018-04-15 00:00:00" & rdate< "2018-05-15 00:00:00"))$WTMP)#ruesink
#max
lay_sk2<-mean((filter(gcsk,rdate>"2018-03-01 00:00:00" & rdate< "2018-05-30 00:00:00"))$WTMP)
lay_fb2<-mean((filter(fb,rdate>"2018-03-01 00:00:00" & rdate< "2018-05-30 00:00:00"))$WTMP)
lay_bf2<-mean((filter(bf,rdate>"2018-03-15 00:00:00" & rdate< "2018-05-30 00:00:00"))$WTMP)
lay_oy2<-mean((filter(oy,rdate>"2018-05-01 00:00:00" & rdate< "2018-07-30 00:00:00"))$WTMP)
lay_wh2<-mean((filter(wh,rdate>"2018-07-01 00:00:00" & rdate< "2018-08-31 00:00:00"))$WTMP)
lay_gb2<-mean((filter(gbj,rdate>"2018-07-01 00:00:00" & rdate< "2018-08-31 00:00:00"))$WTMP)
lay_hm2<-mean((filter(hmi2,rdate>"2018-06-1 00:00:00" & rdate< "2018-07-15 00:00:00"))$WTMP)#inat
lay_wp2<-mean((filter(nah1516,rdate>"2018-06-1 00:00:00" & rdate< "2018-07-15 00:00:00"))$WTMP)#ruesink


```

We had to clean parts of the data to prepare it for analysis. The first issue we had to resolve was the extreme weight and caliper length outliers, which was clearly due to a misplaced decimal or missing 0 during data entry (these data points were off by a factor of 10 from "correct" data). In the silenced part of the markdown, this had to be corrected 5/432 times. 

The second issue was that some snails ran out of food during the growth experiment, which could jeopardize our assumption of unlimited growth while in the common garden experiment. We checked snail consumption three times over the course of the experiment, both to ensure snails had food but also to record which ones ran out of food. The vast majority (391/432) of snails never ran out of food. 40/432 ran out of food once, while 1/432 ran out of food twice. The plot below shows this breakdown, with snails that never ran out food removed. For the purposes of this experiment, we decided to include snails that missed a single meal during the entirety of the experiment, but removed the single case in which a snail ran out of food twice. When we remove these snails that ran out of food once, we get the same results (in terms of models and significance). Further evidence it's ok to include these. 

Further, the second plot below shows that most snails consumed all their food at timepoint 1, followed by timepoint 2 and finally timepoint 3 (seven snails ran out at t3)

```{r,echo=F}

ggplot(consfilter,aes(x=TPC.Label,y=n,group=TPC.Label))+geom_bar(stat="identity")+labs(x="Unique snail code",y="Number of times ran out of food")
ggplot(conscase,aes(x=timepoint,y=n,group=timepoint))+geom_bar(stat="identity")


```

The third issue was that some snails died, or went missing, over the course of the experiment. 37 snails died, and 1 went missing. We removed these snails from consideration, as we could not get a final growth measurement. The two plots below show the distribution of dead snails across site and temperature. Intriguingly, snails tended to died at lower temperatures, especially at 16C. We will see later on this was the temperature of lowest growth as well. 

```{r,echo=F}
ggplot(dead,aes(x=temp,y=n))+geom_bar(stat="identity")+labs(x="Common Garden Temperature",y="Mortalities (n)")

ggplot(deadpop,aes(x=pop,y=n))+geom_bar(stat="identity")+labs(x="Population",y="Mortalities (n)")

```

In, between removing snails that ran out of food twice (n=1), died (n=37), or went missing (n=1), there were 393 snails whose growth rates we kept. 

So, there looks like there could be some significant patterns in survival between populations and common garden temperatures. Do we see that? Let's see at just a population and temperature level. 
```{r,echo=F,warning=F}
growth$dead<-ifelse(growth$alive=="y",0,ifelse(growth$alive=="n",1,NA))
growth$aliven<-ifelse(growth$alive=="y",1,ifelse(growth$alive=="n",0,NA))
alivepoptemp<-growth%>%group_by(temp,pop)%>%dplyr::summarise(alivesum=sum(aliven),.groups="drop")
deadpoptemp<-growth%>%group_by(temp,pop)%>%dplyr::summarise(deadsum=sum(dead),.groups="drop")

empty<-unique(growth[,c('temp','pop')])


survival<-data.frame("site"=empty$pop,"temp"=empty$temp,"dead"=deadpoptemp$deadsum,"alive"=alivepoptemp$alivesum)
y<-cbind(survival$alive,survival$dead)

summary(aov(data=survival,y~site+temp))

predictme<-(glm(y~temp,survival,family=binomial))
predict(predictme,data.frame(temp=30),type="response")
summary(glm(y~site+temp,survival,family=binomial))


#mean vs. season length.
summary(lm(seasonlength10~mean,q,family='gaussian'))
ggplot(q,aes(x=seasonlength10,y=mean))+geom_point()
chart.Correlation(q[,c(2:8)],histogram=TRUE)

chart.Correlation(brkpts[,c(4:8,14,18:21)],histogram=TRUE,method='pearson')
peras<-brkpts[,c(4:8,14,18:21)]
library(ppcor)

cor(peras,method='pearson')


```

Temperature does have an effect, with increasing survivorship with increasing common garden temperature. As for sites, there may be some differences, but we can't tell this way. We will have to use environmental data as a proxy.

```{r,include=FALSE,warning=F,echo=F}
#lat
survival$lat<-ifelse(survival$site=="Beaufort",34.819,
              ifelse(survival$site=="Folly Beach",32.660525,
              ifelse(survival$site=="Great Bay",43.089589,
              ifelse(survival$site=="Humboldt",40.849448,
              ifelse(survival$site=="Oyster", 37.288562,                                                                     ifelse(survival$site=="Woods Hole",41.57687,                                                                   ifelse(survival$site=="Willapa",46.5007,
              ifelse(survival$site=="Skidaway",31.970,NA))))))))                                                                                                                                                                                                                                     
means<-data.frame(with(temp,tapply(WTMP,site,mean)))

#means
survival$mean<-ifelse(survival$site=="Beaufort",means[1,1],
              ifelse(survival$site=="Folly Beach",means[2,1],
              ifelse(survival$site=="Great Bay",means[3,1],
              ifelse(survival$site=="Humboldt",means[5,1],
              ifelse(survival$site=="Oyster",means[7,1],                                                      
              ifelse(survival$site=="Woods Hole",means[8,1],
              ifelse(survival$site=="Willapa",means[6,1],
              ifelse(survival$site=="Skidaway",means[4,1],NA))))))))


#s.mean
survival$s.mean<-ifelse(survival$site=="Beaufort",s.mean[1,1],
              ifelse(survival$site=="Folly Beach",s.mean[2,1],
              ifelse(survival$site=="Great Bay",s.mean[3,1],
              ifelse(survival$site=="Humboldt",s.mean[5,1],
              ifelse(survival$site=="Oyster",s.mean[7,1],                                                      
              ifelse(survival$site=="Woods Hole",s.mean[8,1],
              ifelse(survival$site=="Willapa",s.mean[6,1],
              ifelse(survival$site=="Skidaway",s.mean[4,1],NA))))))))
#q.mean
survival$q.mean<-ifelse(survival$site=="Beaufort",q[4,2],
              ifelse(survival$site=="Folly Beach",q[5,2],
              ifelse(survival$site=="Great Bay",q[1,2],
              ifelse(survival$site=="Humboldt",q[7,2],
              ifelse(survival$site=="Oyster",q[3,2],                                                      
              ifelse(survival$site=="Woods Hole",q[2,2],
              ifelse(survival$site=="Willapa",q[6,2],
              ifelse(survival$site=="Skidaway",q[9,2],NA))))))))
#t.mean
survival$t.mean<-ifelse(survival$site=="Beaufort",q[4,3],
              ifelse(survival$site=="Folly Beach",q[5,3],
              ifelse(survival$site=="Great Bay",q[1,3],
              ifelse(survival$site=="Humboldt",q[7,3],
              ifelse(survival$site=="Oyster",q[3,3],                                                      
              ifelse(survival$site=="Woods Hole",q[2,3],
              ifelse(survival$site=="Willapa",q[6,3],
              ifelse(survival$site=="Skidaway",q[9,3],NA))))))))

#max
survival$max<-ifelse(survival$site=="Beaufort",q[4,4],
              ifelse(survival$site=="Folly Beach",q[5,4],
              ifelse(survival$site=="Great Bay",q[1,4],
              ifelse(survival$site=="Humboldt",q[7,4],
              ifelse(survival$site=="Oyster",q[3,4],                                                      
              ifelse(survival$site=="Woods Hole",q[2,4],
              ifelse(survival$site=="Willapa",q[6,4],
              ifelse(survival$site=="Skidaway",q[9,4],NA))))))))

#seasonlength10
survival$seasonlength10<-ifelse(survival$site=="Beaufort",q[4,7],
              ifelse(survival$site=="Folly Beach",q[5,7],
              ifelse(survival$site=="Great Bay",q[1,7],
              ifelse(survival$site=="Humboldt",q[7,7],
              ifelse(survival$site=="Oyster",q[3,7],                                                      
              ifelse(survival$site=="Woods Hole",q[2,7],
              ifelse(survival$site=="Willapa",q[6,7],
              ifelse(survival$site=="Skidaway",q[9,7],NA))))))))

#seasonlength12
survival$seasonlength12<-ifelse(survival$site=="Beaufort",q[4,8],
              ifelse(survival$site=="Folly Beach",q[5,8],
              ifelse(survival$site=="Great Bay",q[1,8],
              ifelse(survival$site=="Humboldt",q[7,8],
              ifelse(survival$site=="Oyster",q[3,8],                                                      
              ifelse(survival$site=="Woods Hole",q[2,8],
              ifelse(survival$site=="Willapa",q[6,8],
              ifelse(survival$site=="Skidaway",q[9,8],NA))))))))
```

```{r,warning=F, echo=F}

mods.surv<-list(
  "null"=glm(y~1,survival,family=binomial),
  "lat"=glm(y~lat+temp,survival,family=binomial),
  "mean"=glm(y~mean+temp,survival,family=binomial),
  "s.mean"=glm(y~s.mean+temp,survival,family=binomial),
  "q.mean"=glm(y~q.mean+temp,survival,family=binomial),
  "t.mean"=glm(y~t.mean+temp,survival,family=binomial),
  "max"=glm(y~max+temp,survival,family=binomial),
  "seasonlength12"=glm(y~seasonlength12+temp,survival,family=binomial),
  "seasonlength10"=glm(y~seasonlength10+temp,survival,family=binomial),
  "temp"=glm(y~temp,survival,family=binomial))
  

aictab(mods.surv)

summary(mods.surv$temp)

c0<-(0.13375)
c1<-(0.09588)
tempt<-survival$temp
p1=plogis(c0+c1*tempt)
comb<-data.frame(tempt,p1)

ggplot(growth,aes(x=temp,y=aliven))+geom_jitter(height=0.05,size=2)+geom_smooth(data=comb,aes(x=tempt,y=p1),method="glm",method.args=list(family="binomial"),formula=y~x,color="black")+theme_classic()+scale_x_continuous(name="Common Garden Temperature (°C)",breaks=c(16,20,24,26,28,30),labels=c(16,20,24,26,28,30))+scale_y_discrete(name="Survival",breaks=c(0,1),labels=c(0,1),limits=c(0,1))+theme(text=element_text(family="arial",size=22))

```

There is no difference when we look at survival across site, both purely as a comparison between sites as a factor and when we code sites by environmental data. However, survival of juveniles increases with common garden temperature. A cool result!

## Environmental Data

We extracted temperature data from each site. With this data, we calculated different environmental predictors that might explain patterns in growth. 

* "Quantile" (°C)  
  *The average SST of the upper 75th percentile of summer months (06/01/2018 - 09/30/2018)
* "Decile" (°C)
  *The average SST of the upper 90th percentile of summer months (06/01/2018 - 09/30/2018)
* "max" 
  *The maximum SST value recorded during summer months (06/01/2018 - 09/30/2018)
* "mean"  (°C)
  *The mean SST of the site, calculated across the entire year
* "summer mean" (°C)
  *The mean SST of the site, calculated during the summer months (06/01/2018 - 09/30/2018)
* "seasonlength10/16" (days)
  *The number of days where the average daily temperature exceeded a threshold. Here, we use 16C, since this was our lowest temperature in experimentation and resulted in very slow growth (accelerates at 20C) - from Cheng et al. 2017. However, things become signicant when performed at 10C. We can also use 12.5C and get somewhat significant results, after the breakpoint for Oxygen consumption found in Schick's dissertation (Schick 1971) 

We also used latitude as a predictor (not shown in table below)
```{r,include=T,echo=F,warning=F}
#plot of site temperatures
#highlight regions of development
dev_dates<-read.csv(here::here('data/dev_dates.csv'))

dev_dates$xmin<-as.Date(dev_dates$xmin,format="%Y-%m-%d")
dev_dates$xmax<-as.Date(dev_dates$xmax,format="%Y-%m-%d")
dev_dates$ymin<--Inf
dev_dates$ymax<-Inf

dev_dates<-filter(dev_dates,site==c("Great Bay, NH","Skidaway, GA"))


ggplot(data=temp,aes(x=date,y=WTMP,color=site))+scale_fill_viridis_d(name="Site",labels=c("Great Bay, NH","Woods Hole, MA","Oyster, VA","Beaufort, NC","Folly Beach, SC","Skidaway, GA","Willapa, WA","Humboldt, CA"),option="D")+scale_color_viridis_d(name="Site",labels=c("Great Bay, NH","Woods Hole, MA","Oyster, VA","Beaufort, NC","Folly Beach, SC","Skidaway, GA","Willapa, WA","Humboldt, CA"),option="D")+theme_classic()+geom_vline(xintercept = 152)+geom_vline(xintercept = 273)+ylab("SST (°C)")+xlab("")+scale_x_date(date_labels = "%b")+theme(text=element_text(family="sanserif",size=14))+stat_summary(geom="line",fun.y=base::mean,size=2)+guides(color=guide_legend(override.aes=list(fill=NA)))

#north-south  development mean
ggplot(data=temp,aes(x=date,y=WTMP,color=site))+geom_rect(data=data_s,aes(xmin=xmin,xmax=xmax,ymin=ymin,ymax=ymax),fill=("grey"),inherit.aes=F)+geom_rect(data=dev_dates,aes(xmin=xmin,xmax=xmax,ymin=ymin,ymax=ymax,fill=site),alpha=0.2,inherit.aes=F)+scale_fill_manual(name="Site",labels=c("Great Bay, NH","Skidaway, GA"),values=c("yellow","blue"))+scale_color_viridis_d(name="Site",labels=c("Great Bay, NH","Woods Hole, MA","Oyster, VA","Beaufort, NC","Folly Beach, SC","Skidaway, GA","Willapa, WA","Humboldt, CA"),option="D")+theme_classic()+geom_vline(xintercept = 152)+geom_vline(xintercept = 273)+ylab("SST (°C)")+xlab("")+scale_x_date(date_labels = "%b")+theme(text=element_text(family="sanserif",size=14))+stat_summary(geom="line",fun.y=base::mean,size=2)+guides(color=guide_legend(override.aes=list(fill=NA)))+
  geom_segment(aes(y=20,yend=20,x=as.Date("2018-03-01",format="%Y-%m-%d")),xend=as.Date("2018-05-30",format="%Y-%m-%d"),size=2,color="black")+geom_segment(aes(y=22.7,yend=22.7,x=as.Date("2018-07-01",format="%Y-%m-%d")),xend=as.Date("2018-08-31",format="%Y-%m-%d"),size=2,color="black")

#season length
gb_length<-gbj%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>10)
sk_length<-gcsk%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>10)

data_s<-data.frame(xmin=as.Date("2018-01-01",format="%Y-%m-%d"),xmax=as.Date("2018-12-31",format="%Y-%m-%d"),ymin=-Inf,ymax=10)
ggplot(data=temp,aes(x=date,y=WTMP,color=site))+scale_fill_viridis_d(name="Site",labels=c("Great Bay, NH","Woods Hole, MA","Oyster, VA","Beaufort, NC","Folly Beach, SC","Skidaway, GA","Willapa, WA","Humboldt, CA"),option="D")+scale_color_viridis_d(name="Site",labels=c("Great Bay, NH","Woods Hole, MA","Oyster, VA","Beaufort, NC","Folly Beach, SC","Skidaway, GA","Willapa, WA","Humboldt, CA"),option="D")+theme_classic()+geom_vline(xintercept = 152)+geom_vline(xintercept = 273)+ylab("SST (°C)")+xlab("")+scale_x_date(date_labels = "%b")+theme(text=element_text(family="sanserif",size=14))+stat_summary(geom="line",fun.y=base::mean,size=2)+guides(color=guide_legend(override.aes=list(fill=NA)))+geom_rect(data=data_s,aes(xmin=xmin,xmax=xmax,ymin=ymin,ymax=ymax),fill=("grey"),alpha=0.85,inherit.aes=F)
  


q


```

# Data exploration

This data exploration is for linear models only, describing putative TPCs. Therefore, the section below is just for information purposes and is shown collapsed or is silenced- see R code for details. 


## Do sites differ? 

Do populations differ in their growth rate across the common garden experiemnt? Here, ANOVA tells us that growth between sites are significantly different. We are justified in pursuing population and temperature level differences. 
```{r,include=T,warning=F}

anovasites<-(aov(cal.length~pop*temp,data=growth.alive))
summary(anovasites)
growth.alive$pop<-as.factor(growth.alive$pop)


```

## Shell size by population

Should we use end caliper lengths, or do we need to subtract initial caliper length from end caliper length? In other words, do initial caliper lengths differ, requiring us to standardize our growth rate? Here, we find that populations do differ in initial growth. Tukey post-hoc comparisons (silenced, in code) further support this. Thus, we must standardize growth by creating a growth rate of Final size - initial size. The univariate boxplots below also show that while outliers do appear to be present, they can be attributed to population or temperature level differences. 
```{r,echo=F,warning=F}
summary(aov(cal.length.start~pop,data=growth.alive))
```
```{r,include=F,echo=F,warning=F}
summary(anovasites)
#post-hoc test
TukeyHSD(anovasites,"pop")

ggplot(growth.alive,aes(x=temp,y=cal.length,color=pop))+geom_point()+geom_smooth()+facet_wrap(pop~.)



ggplot(growth.alive,aes(x=pop,y=cal.length))+geom_boxplot()

ggplot(growth.alive,aes(x=temp,y=cal.length,group=temp))+geom_boxplot()
```


## Correlations
```{r,include=T,echo=F,warning=F}


M <- (growth.alive[,9:12])
chart.Correlation(M,histogram=TRUE)

```

Here, we see that cal length and weight are both highly correlated. Thus, we will not include weight in any of our models. 


## Residuals of full model 
Here, we investigate the residuals of the full model (lm(cal.length~pop*temp*oce*bin,growth.alive)). This is to check if we need to transform our data, and if our assumptions of normality are warranted.  

```{r,echo=T,warning=F}
growth.alive<-na.omit(growth.alive)
growth.alive.sqrt<-growth.alive
growth.alive.sqrt$cal.length<-(growth.alive$cal.length)^2
fulli<-(lm(cal.length~pop*temp*oce*bin,growth.alive.sqrt))

plot(resid(fulli))
hist(resid(fulli))
skewness(growth.alive.sqrt$cal.length)
#negative skew
growth.alive.sqrt<-tidyr::drop_na(growth.alive.sqrt)
growth.alive.sqrt<-na.omit(growth.alive.sqrt)
```
Things look ok, but maybe log-transforming growth will improve our skew and residual plots.

```{r,echo=T,warning=F}
growth.alive$log_growth<-log(max(growth.alive$cal.length+1)-growth.alive$cal.length)
fulli2<-(lm(log_growth~pop*temp*oce*bin,growth.alive))

plot(fulli2)
plot(resid(fulli2))
hist(resid(fulli2))

skewness(growth.alive$log_growth)
```
While the log transformation improves the skewness slightly, we will assume the distribution of residuals are normal and proceed with untransformed growth rate. 

## Coplots

Other than temperature and population, which we control for, do we see different reactions depending on tupperware bin (our subreplication)? Here, reactions appaer to be the same no matter what bin we used. We do not need to include bin in our models (further supported by AIC below in data analysis). Note: Margins were too big on this figure to include in the markdown - viewable in R console. 
```{r,echo=F}
#dev.off()
#coplot(cal.length~temp |pop*bin,data=growth.alive)

```

# Data Analysis
## Model predictors

We are going to create TPCs for each population by temperature, using both piecewise (segmented) regression and quadratic regression. What predictors should be used in these models?
```{r,echo=F, warning=F}

models<-list(
  "null" = lm(cal.length~1,growth.alive),
  "pop" = lm(cal.length~pop,growth.alive),
  "temp" = lm(cal.length~temp,growth.alive),
  "oce" = lm(cal.length~temp,growth.alive),
  "bin" = lm(cal.length~bin,growth.alive),
  "out" = lm(cal.length~ran.out,growth.alive),
  
  "pop.temp" = lm(cal.length~pop+temp,growth.alive),
  "pop.oce" = lm(cal.length~pop+oce,growth.alive),
  "pop.bin" = lm(cal.length~pop+bin,growth.alive),
  "pop.out" = lm(cal.length~pop+ran.out,growth.alive),
  "temp.oce" = lm(cal.length~oce+temp,growth.alive),
  "temp.bin" = lm(cal.length~bin+temp,growth.alive),
  "oce.bin" = lm(cal.length~bin+oce,growth.alive),
  "temp.out" = lm(cal.length~temp+ran.out,growth.alive),
  "oce.out" = lm(cal.length~oce+ran.out,growth.alive),
  "bin.out" = lm(cal.length~bin+ran.out,growth.alive),
  
  "pop.temp.oce" = lm(cal.length~pop+temp+oce,growth.alive),
  "pop.temp.bin" = lm(cal.length~pop+temp+bin,growth.alive),
  "pop.temp.out" = lm(cal.length~pop+temp+ran.out,growth.alive),
  "oce.temp.bin" = lm(cal.length~oce+temp+bin,growth.alive),
  "oce.temp.out"= lm(cal.length~oce+temp+ran.out,growth.alive),
  "oce.bin.out"=lm(cal.length~oce+bin+ran.out,growth.alive),
  "bin.out.temp" = lm(cal.length~bin+ran.out+temp,growth.alive),
  
  "pop.temp.oce.bin"= lm(cal.length~pop+oce+temp+bin,growth.alive),
  "pop.temp.oce.out" = lm(cal.length~pop+oce+temp+ran.out,growth.alive),
  "temp.oce.bin.out"= lm(cal.length~bin+oce+temp+ran.out,growth.alive),
  
  "fulla" = lm(cal.length~pop+temp+oce+bin+ran.out,growth.alive),
  
  
  "pop*temp" = lm(cal.length~pop*temp,growth.alive),
  "pop*oce" = lm(cal.length~pop*oce,growth.alive),
  "pop*bin" = lm(cal.length~pop*bin,growth.alive),
  "temp*oce" = lm(cal.length~oce*temp,growth.alive),
  "temp*bin" = lm(cal.length~bin*temp,growth.alive),
  "oce*bin" = lm(cal.length~bin*oce,growth.alive),
  "pop*out" = lm(cal.length~pop*ran.out,growth.alive),
  "temp*out" = lm(cal.length~temp*ran.out,growth.alive),
  "oce*out" = lm(cal.length~oce*ran.out,growth.alive),
  "bin*out" = lm(cal.length~bin*ran.out,growth.alive),
  
  "pop*temp*oce" = lm(cal.length~pop*temp*oce,growth.alive),
  "pop*temp*bin" = lm(cal.length~pop*temp*bin,growth.alive),
  "pop*temp*out" = lm(cal.length~pop*temp*ran.out,growth.alive),
  "oce*temp*bin" = lm(cal.length~oce*temp*bin,growth.alive),
  "oce*temp*out"= lm(cal.length~oce*temp*ran.out,growth.alive),
  "oce*bin*out"=lm(cal.length~oce*bin*ran.out,growth.alive),
  "bin*out*temp" = lm(cal.length~bin*ran.out*temp,growth.alive),
  
  "pop*temp*oce*bin"= lm(cal.length~pop*oce*temp*bin,growth.alive),
  "pop*temp*oce*out" = lm(cal.length~pop*oce*temp*ran.out,growth.alive),
  "temp*oce*bin*out"= lm(cal.length~bin*oce*temp*ran.out,growth.alive),
  
  "fulli" = lm(cal.length~pop*temp*oce*bin*ran.out,growth.alive))

aictab(models)

```
Here, we see that a few models are well supported. We choose the interactive pop*temp model only because 1) the additive model only tells us if populations are different at each temperature, while the interactive model also tells us the populations slopes with temperature and gives us a TPC 2) oce adds nothing to the models, so is removed. 3) Looking at our coplots of bin, bin had no effect on growth. 

```{r,echo=F}
summary(models$"pop*temp")

```

Based on this supported model structure, we will construct segmented and quadratic models that follow this formulation: growth~pop*temp. 

## Broken Stick regression

It's hard to compare TPC against one another. One method we've settled on is the use of broken stick regression to allow us to quantify the shape of the reaction as well as the thermal optima (x) and the maximal trait performance (y). Here, we used the segmented package to create single-optima broken stick regressions that also allow us to extract optimas.

We used a separate model for each population, as segmented does not allow for grouping. We used the following formulation: glm(shell length ~ temperature, population,family=gaussian), such that we modeled the response of shell lengths from a single population to temperature. 

```{r,include=T,echo=F,warning=F}
#create dataframes by population so 
bf<-filter(growth.alive,pop=="Beaufort")
fb<-filter(growth.alive,pop=="Folly Beach")
gb<-filter(growth.alive,pop=="Great Bay")
hm<-filter(growth.alive,pop=="Humboldt")
oy<-filter(growth.alive,pop=="Oyster")
sk<-filter(growth.alive,pop=="Skidaway")
wp<-filter(growth.alive,pop=="Willapa")
wh<-filter(growth.alive,pop=="Woods Hole")

#creates segmented models for each population over the common garden temperatures
m.wh<-glm(cal.length~temp,wh,family=gaussian)
seg.wh<-segmented(m.wh,seg.Z = ~temp, psi=24,seg.control(maxit.glm=100),fix.npsi=T,n.boot=500)

m.gb<-glm(cal.length~temp,gb,family=gaussian)
seg.gb<-segmented(m.gb,seg.Z = ~temp, psi=26,seg.control(maxit.glm=100),fix.npsi=T,n.boot=500)

m.oy<-glm(cal.length~temp,oy,family=gaussian)
seg.oy<-segmented(m.oy,seg.Z = ~temp, psi=24)

m.bf<-glm(cal.length~temp,bf,family=gaussian)
seg.bf<-segmented(m.bf,seg.Z = ~temp, psi=24)

m.fb<-glm(cal.length~temp,fb,family=gaussian)
seg.fb<-segmented(m.fb,seg.Z = ~temp, psi=24)

m.sk<-glm(cal.length~temp,sk,family=gaussian)
seg.sk<-segmented(m.sk,seg.Z = ~temp, psi=22,seg.control(maxit.glm=100),fix.npsi=T,n.boot=500)

hm<-na.omit(hm)
m.hm<-glm(cal.length~temp,hm,family=gaussian)
seg.hm<-segmented(m.hm,seg.Z = ~temp, psi=24)

m.wp<-glm(cal.length~temp,wp,family=gaussian)
seg.wp<-segmented(m.wp,seg.Z = ~temp, psi=24)





xmin<-min(growth.alive$temp,na.rm=T)
xmax<-max(growth.alive$temp,na.rm=T)

all.length.seg<-list(seg.gb,seg.wh,seg.oy,seg.bf,seg.fb,seg.sk,seg.wp,seg.hm)


##plotting predicted values
predicted.gb<-data.frame(temp=seq(xmin,xmax,length.out=100))
predicted.gb$cal.length<-predict(seg.gb,predicted.gb)
predicted.gb$pop<-"gb"
predicted.gb$oce<-"a"

predicted.wh<-data.frame(temp=seq(xmin,xmax,length.out=100))
predicted.wh$cal.length<-predict(seg.wh,predicted.wh)
predicted.wh$pop<-"wh"
predicted.wh$oce<-"a"

predicted.oy<-data.frame(temp=seq(xmin,xmax,length.out=100))
predicted.oy$cal.length<-predict(seg.oy,predicted.oy)
predicted.oy$pop<-"oy"
predicted.oy$oce<-"a"

predicted.bf<-data.frame(temp=seq(xmin,xmax,length.out=100))
predicted.bf$cal.length<-predict(seg.bf,predicted.bf)
predicted.bf$pop<-"bf"
predicted.bf$oce<-"a"

predicted.fb<-data.frame(temp=seq(xmin,xmax,length.out=100))
predicted.fb$cal.length<-predict(seg.fb,predicted.fb)
predicted.fb$pop<-"fb"
predicted.fb$oce<-"a"

predicted.sk<-data.frame(temp=seq(xmin,xmax,length.out=100))
predicted.sk$cal.length<-predict(seg.sk,predicted.sk)
predicted.sk$pop<-"sk"
predicted.sk$oce<-"a"

predicted.wp<-data.frame(temp=seq(xmin,xmax,length.out=100))
predicted.wp$cal.length<-predict(seg.wp,predicted.wp)
predicted.wp$pop<-"wp"
predicted.wp$oce<-"p"

predicted.hm<-data.frame(temp=seq(xmin,xmax,length.out=100))
predicted.hm$cal.length<-predict(seg.hm,predicted.hm)
predicted.hm$pop<-"hm"
predicted.hm$oce<-"p"



#combine predicted values into a single dataframe
all.length.pred<-rbind(predicted.gb,predicted.wh,predicted.oy,predicted.bf,predicted.fb,predicted.sk,predicted.wp,predicted.hm)
all.length.pred$population<-all.length.pred$pop
all.length.pred$population<-factor(all.length.pred$population,levels=c("gb","wh","oy","bf","fb","sk","wp","hm"))

all.length.pred$pop<-factor(all.length.pred$pop,levels=c("gb","wh","oy","bf","fb","sk","wp","hm"))


all.length.pred$pop<-ifelse(all.length.pred$pop=="gb","Great Bay",ifelse(all.length.pred$pop=="wh","Woods Hole",ifelse(all.length.pred$pop=="oy","Oyster",ifelse(all.length.pred$pop=="bf","Beaufort",ifelse(all.length.pred$pop=="fb","Folly Beach",ifelse(all.length.pred$pop=="sk","Skidaway",ifelse(all.length.pred$pop=="wp","Willapa",ifelse(all.length.pred$pop=="hm","Humboldt",NA))))))))

all.length.pred$pop<-as.factor(all.length.pred$pop)
all.length.pred$pop<-factor(all.length.pred$pop,levels=c("Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"))

#give growth alive same pop codes
growth.alive$population<-ifelse(growth.alive$pop=="gb","Great Bay",ifelse(growth.alive$pop=="wh","Woods Hole",ifelse(growth.alive$pop=="oy","Oyster",ifelse(growth.alive$pop=="bf","Beaufort",ifelse(growth.alive$pop=="fb","Folly Beach",ifelse(growth.alive$pop=="sk","Skidaway",ifelse(growth.alive$pop=="wp","Willapa",ifelse(growth.alive$pop=="hm","Humboldt",NA))))))))

growth.alive$pop<-as.factor(growth.alive$pop)
growth.alive$population<-factor(growth.alive$pop,levels=c("Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"))
growth.alive$pop<-factor(growth.alive$pop,levels=c("Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"))


##unified breakpoints
ggplot(all.length.pred,aes(x=temp,y=cal.length))+geom_line(aes(group=population,x=temp,y=cal.length,color=population,linetype=population,size=population),size=1.5)+
  ylab("Growth Rate (mm)")+xlab("Common Garden Temperature (°C)")+theme_classic()+
  scale_x_continuous(breaks=c(16,20,24,26,28,30))+
  scale_linetype_manual(values=c(1,1,1,1,1,1,4,4),labels=c("Great Bay, NH","Woods Hole, MA","Oyster, VA","Beaufort, NC","Folly Beach, SC","Skidaway, GA","Willapa, WA","Humboldt, CA"),name="Population")+
  scale_size_manual(values=c(1.2,1.2,1.2,1.2,1.2,1.2,1.2,1.2),labels=c("Great Bay, NH","Woods Hole, MA","Oyster, VA","Beaufort, NC","Folly Beach, SC","Skidaway, GA","Willapa, WA","Humboldt, CA"),name="Population")+
  scale_color_manual(values=c("dark violet","navy","forest green","gold","dark orange","tomato","dark violet","navy"),labels=c("Great Bay, NH","Woods Hole, MA","Oyster, VA","Beaufort, NC","Folly Beach, SC","Skidaway, GA","Willapa, WA","Humboldt, CA"),name="Population")+theme(text=element_text(family="arial",size=22))

ggplot()+geom_boxplot(data=growth.alive,aes(x=temp,y=cal.length,group=interaction(pop,temp),color=pop,fill=pop),alpha=0.4)+scale_color_manual(values=c("dark violet","navy","forest green","gold","dark orange","tomato","dark violet","navy"),labels=c("Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"),name="Population")+scale_fill_manual(values=c(NA,NA,NA,NA,NA,NA,"gray","gray","gray"),labels=c("Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"),name="Population")+new_scale_color()+new_scale_fill()+geom_line(data=all.length.pred,aes(x=temp,y=cal.length,group=population,color=population,linetype=population,size=population))+
  ylab("Shell Length (mm)")+xlab("Common Garden Temperature (°C)")+theme_classic()+
  scale_x_continuous(breaks=c(16,20,24,26,28,30))+
  scale_linetype_manual(values=c(1,1,1,1,1,1,4,4),labels=c("Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"),name="Population")+
  scale_size_manual(values=c(1.2,1.2,1.2,1.2,1.2,1.2,1.2,1.2),labels=c("Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"),name="Population")+
  scale_color_manual(values=c("dark violet","navy","forest green","gold","dark orange","tomato","dark violet","navy"),labels=c("Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"),name="Population")+theme(text=element_text(family="arial",size=22))



##facetted with points
all.length.pred<-all.length.pred%>%
  mutate(pop = fct_relevel(pop, 
            "Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"))

ggplot()+geom_line(data=all.length.pred,aes(group=pop,x=temp,y=cal.length,color=pop,linetype=pop,size=pop),size=1.5)+
  ylab("Shell Growth (mm)")+xlab("Temperature (°C)")+theme_classic()+
  scale_x_continuous(breaks=c(16,20,24,26,28,30))+
  scale_linetype_manual(values=c(1,1,1,1,1,1,4,4),labels=c("Great Bay, NH","Woods Hole, MA","Oyster, VA","Beaufort, NC","Folly Beach, SC","Skidaway, GA","Willapa, WA","Humboldt, CA"),name="Population")+
  scale_size_manual(values=c(1.2,1.2,1.2,1.2,1.2,1.2,1.2,1.2),labels=c("Great Bay, NH","Woods Hole, MA","Oyster, VA","Beaufort, NC","Folly Beach, SC","Skidaway, GA","Willapa, WA","Humboldt, CA"),name="Population")+
  scale_color_manual(values=c("dark violet","navy","forest green","gold","dark orange","tomato","dark violet","navy"),labels=c("Great Bay, NH","Woods Hole, MA","Oyster, VA","Beaufort, NC","Folly Beach, SC","Skidaway, GA","Willapa, WA","Humboldt, CA"),name="Population")+theme(text=element_text(family="arial",size=22),legend.position = "none")+geom_point(data=growth.alive,aes(x=temp,y=cal.length,group=pop))+facet_wrap(pop~.)


#for figure
lengthTPC<-ggplot(all.length.pred,aes(x=temp,y=cal.length))+geom_line(aes(group=population,x=temp,y=cal.length,color=population,linetype=population,size=population))+
  ylab("Shell Length (mm)")+xlab("Common Garden Temperature (°C)")+theme_classic()+
  scale_x_continuous(breaks=c(16,20,24,26,28,30))+
  scale_linetype_manual(values=c(1,1,1,1,1,1,4,4),labels=c("Great Bay, NH","Woods Hole, MA","Oyster, VA","Beaufort, NC","Folly Beach, SC","Skidaway, GA","Willapa, WA","Humboldt, CA"),name="Population")+
  scale_size_manual(values=c(1.2,1.2,1.2,1.2,1.2,1.2,1.2,1.2),labels=c("Great Bay, NH","Woods Hole, MA","Oyster, VA","Beaufort, NC","Folly Beach, SC","Skidaway, GA","Willapa, WA","Humboldt, CA"),name="Population")+
  scale_color_manual(values=c("dark violet","navy","forest green","gold","dark orange","tomato","dark violet","navy"),labels=c("Great Bay, NH","Woods Hole, MA","Oyster, VA","Beaufort, NC","Folly Beach, SC","Skidaway, GA","Willapa, WA","Humboldt, CA"),name="Population")+theme(text=element_text(family="arial",size=22))+theme(text=element_text(family="arial",size=22))+theme(legend.position = "none") 
lengthTPC
```

 Here, I show the segmented model fits both on a single plot and facetted to show spread of points. Just by eyeballing the results, we see that more or less the northern sites have optima above those of southern sites. We will test for this later. First, how confident are we in these breakpoints? The tests below tell us.
 
* P-score: The P-score tests the null hypothesis for no difference in slopes, i.e. no breakpoint. If P is below 0.05, then there is a breakpoint. We see here that all p-scores are signficant, and thus breakpoints do exist in our data
 
* Davies test: we perform this analysis, but is less powerful for one breakpoint analyses. I am not certain what this means, since the null hypothesis is no breakpoint but we get radically different results this way.
 
*  CI Low/High: Confidence interval of the breakpoint
 
* Breakpoint: Thermal optima breakpoint
 
 
```{r,echo=F,warning=F,include=F}
scores<-data.frame("site" = c("Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"),"breakpoint"=NA,"P Score"=NA,"Davies Test"=NA,"slope1"=NA,"CI slope 1"=NA,"slope2"=NA,"CI slope 2"=NA)

#brkpts x
scores[1,2]<-confint(seg.gb)[[1]]
scores[2,2]<-confint(seg.wh)[[1]]
scores[3,2]<-confint(seg.oy)[[1]]
scores[4,2]<-confint(seg.bf)[[1]]
scores[5,2]<-confint(seg.fb)[[1]]
scores[6,2]<-confint(seg.sk)[[1]]
scores[7,2]<-confint(seg.wp)[[1]]
scores[8,2]<-confint(seg.hm)[[1]]
#pscore
scores[1,3]<-pscore.test(seg.gb,~temp)[[5]]
scores[2,3]<-pscore.test(seg.wh,~temp)[[5]]
scores[3,3]<-pscore.test(seg.oy,~temp)[[5]]
scores[4,3]<-pscore.test(seg.bf,~temp)[[5]]
scores[5,3]<-pscore.test(seg.fb,~temp)[[5]]
scores[6,3]<-pscore.test(seg.sk,~temp)[[5]]
scores[7,3]<-pscore.test(seg.wp,~temp)[[5]]
scores[8,3]<-pscore.test(seg.hm,~temp)[[5]]
#davies
scores[1,4]<-davies.test(seg.gb,~temp)[[5]]
scores[2,4]<-davies.test(seg.wh,~temp)[[5]]
scores[3,4]<-davies.test(seg.oy,~temp)[[5]]
scores[4,4]<-davies.test(seg.bf,~temp)[[5]]
scores[5,4]<-davies.test(seg.fb,~temp)[[5]]
scores[6,4]<-davies.test(seg.sk,~temp)[[5]]
scores[7,4]<-davies.test(seg.wp,~temp)[[5]]
scores[8,4]<-davies.test(seg.hm,~temp)[[5]]
#slope1
scores[1,5]<-as.data.frame(slope(seg.gb))[1,1]
scores[2,5]<-as.data.frame(slope(seg.wh))[1,1]
scores[3,5]<-as.data.frame(slope(seg.oy))[1,1]
scores[4,5]<-as.data.frame(slope(seg.bf))[1,1]
scores[5,5]<-as.data.frame(slope(seg.fb))[1,1]
scores[6,5]<-as.data.frame(slope(seg.sk))[1,1]
scores[7,5]<-as.data.frame(slope(seg.wp))[1,1]
scores[8,5]<-as.data.frame(slope(seg.hm))[1,1]  
#slope1Ci  
scores[1,6]<-as.data.frame(slope(seg.gb))[1,1]-as.data.frame(slope(seg.gb))[1,4]
scores[2,6]<-as.data.frame(slope(seg.wh))[1,1]-as.data.frame(slope(seg.wh))[1,4]
scores[3,6]<-as.data.frame(slope(seg.oy))[1,1]-as.data.frame(slope(seg.oy))[1,4]
scores[4,6]<-as.data.frame(slope(seg.bf))[1,1]-as.data.frame(slope(seg.bf))[1,4]
scores[5,6]<-as.data.frame(slope(seg.fb))[1,1]-as.data.frame(slope(seg.fb))[1,4]
scores[6,6]<-as.data.frame(slope(seg.sk))[1,1]-as.data.frame(slope(seg.sk))[1,4]
scores[7,6]<-as.data.frame(slope(seg.wp))[1,1]-as.data.frame(slope(seg.wp))[1,4]
scores[8,6]<-as.data.frame(slope(seg.hm))[1,1]-as.data.frame(slope(seg.hm))[1,4]
#slope2
scores[1,7]<-as.data.frame(slope(seg.gb))[2,1]
scores[2,7]<-as.data.frame(slope(seg.wh))[2,1]
scores[3,7]<-as.data.frame(slope(seg.oy))[2,1]
scores[4,7]<-as.data.frame(slope(seg.bf))[2,1]
scores[5,7]<-as.data.frame(slope(seg.fb))[2,1]
scores[6,7]<-as.data.frame(slope(seg.sk))[2,1]
scores[7,7]<-as.data.frame(slope(seg.wp))[2,1]
scores[8,7]<-as.data.frame(slope(seg.hm))[2,1]
#slope2ci
scores[1,8]<-as.data.frame(slope(seg.gb))[2,1]-as.data.frame(slope(seg.gb))[2,4]
scores[2,8]<-as.data.frame(slope(seg.wh))[2,1]-as.data.frame(slope(seg.wh))[2,4]
scores[3,8]<-as.data.frame(slope(seg.oy))[2,1]-as.data.frame(slope(seg.oy))[2,4]
scores[4,8]<-as.data.frame(slope(seg.bf))[2,1]-as.data.frame(slope(seg.bf))[2,4]
scores[5,8]<-as.data.frame(slope(seg.fb))[2,1]-as.data.frame(slope(seg.fb))[2,4]
scores[6,8]<-as.data.frame(slope(seg.sk))[2,1]-as.data.frame(slope(seg.sk))[2,4]
scores[7,8]<-as.data.frame(slope(seg.wp))[2,1]-as.data.frame(slope(seg.wp))[2,4]
scores[8,8]<-as.data.frame(slope(seg.hm))[2,1]-as.data.frame(slope(seg.hm))[2,4]

scores
write.csv(scores,"C:/Users/drewv/Documents/UMASS/data/length_slopes.csv",row.names=F)
```
```{r}
subset(scores[,c(1:2,5:8)])
```

## Breakpoint analysis, broken stick

To be able to complete statistical analysis of the differences in TPC curves, I extracted the x and y componenets of each curve to give me the thermal optima and maximal trait performance, respectively. This extraction is silenced in code. Once we have extracted the thermal optima and maximal trait performance, we can move on to the relationship between environment and each breakpoint componenet. 

```{r,include=F,echo=F,warning=F}
brkpts<-data.frame(matrix(,nrow=8,ncol=19))
colnames(brkpts)<-c("pop","brkptx","brkpty","lat","mean","s.mean","q.mean","t.mean","oce","brkptx_se","se_lower","se_higher","brkpty_se","max","NA","brkptyq","brkptxq","seasonlength10","seasonlength12")

brkpts$pop<-c("Willapa","Humboldt","Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway")

brkpts[1,2]<-seg.wp$psi[[2]]
brkpts[2,2]<-seg.hm$psi[[2]]
brkpts[3,2]<-seg.gb$psi[[2]]
brkpts[4,2]<-seg.wh$psi[[2]]
brkpts[5,2]<-seg.oy$psi[[2]]
brkpts[6,2]<-seg.bf$psi[[2]]
brkpts[7,2]<-seg.fb$psi[[2]]
brkpts[8,2]<-seg.sk$psi[[2]]


brkpts[1,3]<-(seg.wp$psi[[2]]*coef(seg.wp)[[2]])+(coef(seg.wp)[[1]])
brkpts[2,3]<-(seg.hm$psi[[2]]*coef(seg.hm)[[2]])+(coef(seg.hm)[[1]])
brkpts[3,3]<-(seg.gb$psi[[2]]*coef(seg.gb)[[2]])+(coef(seg.gb)[[1]])
brkpts[4,3]<-(seg.wh$psi[[2]]*coef(seg.wh)[[2]])+(coef(seg.wh)[[1]])
brkpts[5,3]<-(seg.oy$psi[[2]]*coef(seg.oy)[[2]])+(coef(seg.oy)[[1]])
brkpts[6,3]<-(seg.bf$psi[[2]]*coef(seg.bf)[[2]])+(coef(seg.bf)[[1]])
brkpts[7,3]<-(seg.fb$psi[[2]]*coef(seg.fb)[[2]])+(coef(seg.fb)[[1]])
brkpts[8,3]<-(seg.sk$psi[[2]]*coef(seg.sk)[[2]])+(coef(seg.sk)[[1]])


#lat
brkpts$lat<-ifelse(brkpts$pop=="Beaufort",34.819,ifelse(brkpts$pop=="Folly Beach",32.660525,
                                                        ifelse(brkpts$pop=="Great Bay",43.089589,ifelse(brkpts$pop=="Humboldt",40.849448,ifelse(brkpts$pop=="Oyster",
                                                                                                                                                37.288562,ifelse(brkpts$pop=="Tomales",38.12805,ifelse(brkpts$pop=="Woods Hole",41.57687,ifelse(brkpts$pop=="Willapa",46.5007,ifelse(brkpts$pop=="Skidaway",31.970
,NA)))))))))

means<-data.frame(with(temp,tapply(WTMP,site,mean)))

#means
brkpts[1,5]<-means[7,1]#wp
brkpts[2,5]<-means[8,1]#hm
brkpts[3,5]<-means[1,1]#gb
brkpts[4,5]<-means[2,1]#wh
brkpts[5,5]<-means[3,1]#oy
brkpts[6,5]<-means[4,1]#bf
brkpts[7,5]<-means[5,1]#fb
brkpts[8,5]<-means[6,1]#sk


#s.mean
brkpts[1,6]<-s.mean[6,1]
brkpts[2,6]<-s.mean[5,1]
brkpts[3,6]<-s.mean[3,1]
brkpts[4,6]<-s.mean[8,1]
brkpts[5,6]<-s.mean[7,1]
brkpts[6,6]<-s.mean[1,1]
brkpts[7,6]<-s.mean[2,1]
brkpts[8,6]<-s.mean[4,1]


#q.mean
brkpts[1,7]<-q[6,2]
brkpts[2,7]<-q[7,2]
brkpts[3,7]<-q[1,2]
brkpts[4,7]<-q[2,2]
brkpts[5,7]<-q[3,2]
brkpts[6,7]<-q[4,2]
brkpts[7,7]<-q[5,2]
brkpts[8,7]<-q[9,2]


#t.mean
brkpts[1,8]<-q[6,3]
brkpts[2,8]<-q[7,3]
brkpts[3,8]<-q[1,3]
brkpts[4,8]<-q[2,3]
brkpts[5,8]<-q[3,3]
brkpts[6,8]<-q[4,3]
brkpts[7,8]<-q[5,3]
brkpts[8,8]<-q[9,3]


#max
brkpts[1,14]<-q[6,4]
brkpts[2,14]<-q[7,4]
brkpts[3,14]<-q[1,4]
brkpts[4,14]<-q[2,4]
brkpts[5,14]<-q[3,4]
brkpts[6,14]<-q[4,4]
brkpts[7,14]<-q[5,4]
brkpts[8,14]<-q[9,4]


#seasonlength10
brkpts[1,18]<-q[6,7]
brkpts[2,18]<-q[7,7]
brkpts[3,18]<-q[1,7]
brkpts[4,18]<-q[2,7]
brkpts[5,18]<-q[3,7]
brkpts[6,18]<-q[4,7]
brkpts[7,18]<-q[5,7]
brkpts[8,18]<-q[9,7]


#seasonlength12
brkpts[1,19]<-q[6,8]
brkpts[2,19]<-q[7,8]
brkpts[3,19]<-q[1,8]
brkpts[4,19]<-q[2,8]
brkpts[5,19]<-q[3,8]
brkpts[6,19]<-q[4,8]
brkpts[7,19]<-q[5,8]
brkpts[8,19]<-q[9,8]

#brkptx_se
brkpts[1,10]<-seg.wp$psi[[3]]
brkpts[2,10]<-seg.hm$psi[[3]]
brkpts[3,10]<-seg.gb$psi[[3]]
brkpts[4,10]<-seg.wh$psi[[3]]
brkpts[5,10]<-seg.oy$psi[[3]]
brkpts[6,10]<-seg.bf$psi[[3]]
brkpts[7,10]<-seg.fb$psi[[3]]
brkpts[8,10]<-seg.sk$psi[[3]]

#lower bounds brkptx_se2
brkpts[1,11]<-brkpts[1,2]-brkpts[1,10]
brkpts[2,11]<-brkpts[2,2]-brkpts[2,10]
brkpts[3,11]<-brkpts[3,2]-brkpts[3,10]
brkpts[4,11]<-brkpts[4,2]-brkpts[4,10]
brkpts[5,11]<-brkpts[5,2]-brkpts[5,10]
brkpts[6,11]<-brkpts[6,2]-brkpts[6,10]
brkpts[7,11]<-brkpts[7,2]-brkpts[7,10]
brkpts[8,11]<-brkpts[8,2]-brkpts[8,10]

#upper bounds brkpts_se
brkpts[1,12]<-brkpts[1,2]+brkpts[1,10]
brkpts[2,12]<-brkpts[2,2]+brkpts[2,10]
brkpts[3,12]<-brkpts[3,2]+brkpts[3,10]
brkpts[4,12]<-brkpts[4,2]+brkpts[4,10]
brkpts[5,12]<-brkpts[5,2]+brkpts[5,10]
brkpts[6,12]<-brkpts[6,2]+brkpts[6,10]
brkpts[7,12]<-brkpts[7,2]+brkpts[7,10]
brkpts[8,12]<-brkpts[8,2]+brkpts[8,10]

#se for y value calculation
brkpts[1,13]<-(brkpts[1,12]*coef(seg.wp)[[2]])+(coef(seg.wp)[[1]])
brkpts[2,13]<-(brkpts[2,12]*coef(seg.hm)[[2]])+(coef(seg.hm)[[1]])
brkpts[3,13]<-(brkpts[3,12]*coef(seg.gb)[[2]])+(coef(seg.gb)[[1]])
brkpts[4,13]<-(brkpts[4,12]*coef(seg.wh)[[2]])+(coef(seg.wh)[[1]])
brkpts[5,13]<-(brkpts[5,12]*coef(seg.oy)[[2]])+(coef(seg.oy)[[1]])
brkpts[6,13]<-(brkpts[6,12]*coef(seg.bf)[[2]])+(coef(seg.bf)[[1]])
brkpts[7,13]<-(brkpts[7,12]*coef(seg.fb)[[2]])+(coef(seg.fb)[[1]])
brkpts[8,13]<-(brkpts[8,12]*coef(seg.sk)[[2]])+(coef(seg.sk)[[1]])




brkpts$oce<-ifelse(brkpts$pop=="Beaufort","a",ifelse(brkpts$pop=="Folly Beach","a",ifelse(brkpts$pop=="Great Bay","a",ifelse(brkpts$pop=="Humboldt","p",ifelse(brkpts$pop=="Oyster","a",ifelse(brkpts$pop=="Tomales","p",ifelse(brkpts$pop=="Woods Hole","a",ifelse(brkpts$pop=="Willapa","p",ifelse(brkpts$pop=="Skidaway","a",NA)))))))))

brkpts$seasonlength10<-as.numeric(brkpts$seasonlength10)
brkpts$seasonlength12<-as.numeric(brkpts$seasonlength12)
brkpts$pop<-as.factor(brkpts$pop)

brkpts$spring<-NA
brkpts[8,20]<-lay_sk
brkpts[7,20]<-lay_fb
brkpts[6,20]<-lay_bf
brkpts[5,20]<-lay_oy
brkpts[4,20]<-lay_wh
brkpts[3,20]<-lay_gb
brkpts[2,20]<-lay_hm
brkpts[1,20]<-lay_wp

brkpts$spring2<-NA
brkpts[8,21]<-lay_sk2
brkpts[7,21]<-lay_fb2
brkpts[6,21]<-lay_bf2
brkpts[5,21]<-lay_oy2
brkpts[4,21]<-lay_wh2
brkpts[3,21]<-lay_gb2
brkpts[2,21]<-lay_hm2
brkpts[1,21]<-lay_wp2

#write.csv(brkpts,"C:/Users/drewv/Documents/UMASS/data/length_brkpts.csv",row.names=F)


#correlative environmental plots
#mean
mean_plot<-ggplot(brkpts,aes(x=lat,y=mean))+geom_point(aes(color=oce,shape=oce),size=3)+theme_classic()+theme(text=element_text(family="arial",size=22))+
    scale_color_manual(labels=c("Atlantic","Pacific"),name="Ocean", values=c('red','blue'))+
    scale_fill_manual(labels=c("Atlantic","Pacific"),name="Ocean", values=c('red','blue'))+ylab("Mean (°C)")+xlab("Latitude")+
  scale_shape_manual(labels=c("Atlantic","Pacific"),name="Ocean",values=c(16,17))
summary(lm(mean~lat,brkpts,fmaily="gaussian"))
#season length
season_plot<-ggplot(brkpts,aes(x=lat,y=seasonlength10))+geom_point(aes(color=oce,shape=oce),size=3)+theme_classic()+theme(text=element_text(family="arial",size=22))+
    scale_color_manual(labels=c("Atlantic","Pacific"),name="Ocean", values=c('red','blue'))+
    scale_fill_manual(labels=c("Atlantic","Pacific"),name="Ocean", values=c('red','blue'))+ylab("Season Length (10 °C)")+xlab("Latitude")+
    scale_shape_manual(labels=c("Atlantic","Pacific"),name="Ocean",values=c(16,17))
summary(lm(seasonlength10~lat,brkpts,fmaily="gaussian"))

#maximal spawning period
maxspawn_plot<-ggplot(brkpts,aes(x=lat,y=spring2))+geom_point(aes(color=oce,shape=oce),size=3)+theme_classic()+theme(text=element_text(family="arial",size=22))+
    scale_color_manual(labels=c("Atlantic","Pacific"),name="Ocean", values=c('red','blue'))+
    scale_fill_manual(labels=c("Atlantic","Pacific"),name="Ocean", values=c('red','blue'))+ylab("Maximum Spawning Period Mean (°C)")+xlab("Latitude")+
    scale_shape_manual(labels=c("Atlantic","Pacific"),name="Ocean",values=c(16,17))
summary(lm(spring2~lat,brkpts,fmaily="gaussian"))


ggsave(filename="mean_plot.svg",width=5,height=4,dpi=300,units="in",device="svg")
ggsave(filename="season_plot.svg",season_plot,width=5,height=4,dpi=300,units="in",device="svg")
ggsave(filename="maxspawn_plot.svg",maxspawn_plot,width=5,height=4,dpi=300,units="in",device="svg")



```

### Maximum trait Performance (y axis), broken stick

The AIC table below tells us which environmental predictors best describe the relationship of maximal trait performance across populations. 

```{r,include=T,echo=F,warning=F}
##Maximal trait performance (y)
mods.brk<-list(
  "nullo"=glm(brkpty~1,brkpts,family="gaussian"),
  "lat"=glm(brkpty~lat,brkpts,family="gaussian"),
  "mean"=glm(brkpty~mean,brkpts,family="gaussian"),
  "s.mean"=glm(brkpty~s.mean,brkpts,family="gaussian"),
  "q.mean"=glm(brkpty~q.mean,brkpts,family="gaussian"),
  "t.mean"=glm(brkpty~t.mean,brkpts,family="gaussian"),
  "seasonlength10"=glm(brkpty~seasonlength10,brkpts,family="gaussian"),
  "seasonlength12"=glm(brkpty~seasonlength12,brkpts,family="gaussian"),
  "omax"=glm(brkpty~max,brkpts,family="gaussian"),
  "spring"=glm(brkpty~spring,brkpts,family="gaussian"),
   "spring2"=glm(brkpty~spring2,brkpts,family="gaussian")
  
    )

aictab(mods.brk)
```

Here, it appears that the season length as calculated at 10C without ocean is the best predictor. This is followed by latitude, mean sst, and season length calculated at 12.5C, all without ocean. Latitude doesn't tell us much about the environment, so let's take a look at how both season length metrics we calculated perform when calculating maximal trait performance.

#### Maximal trait performance, season length = 12.5 C

```{r,include=T,warning=F,echo=F}
##Maximal trait performance (y)

brkptym<-(lm(brkpty~seasonlength10,brkpts))
summary(brkptym) 


ggplot(brkpts,aes(x=seasonlength12,y=brkpty))+
  geom_point(size=3,aes(color=oce))+theme_classic()+
  ylab("Maximal Growth (mm)")+
  xlab("Season Length (days), 12.5°C")+
  theme(text=element_text(family="arial",size=22))+
    scale_color_manual(labels=c("Atlantic","Pacific"),name="Ocean", values=c('red','blue'))+
    scale_fill_manual(labels=c("Atlantic","Pacific"),name="Ocean", values=c('red','blue'))+
  geom_smooth(method='lm',se=F,color="black")
```

#### Maximal trait performance, season length = 10 C

```{r,warning=F,echo=F}

brkptym2<-(lm(brkpty~seasonlength10,brkpts))
summary(brkptym2) 

ggplot(brkpts,aes(x=seasonlength10,y=brkpty))+
  geom_point(size=3,aes(color=oce,shape=oce))+theme_classic()+
  ylab("Maximal Growth (mm)")+
  xlab("Season Length (days), 10°C")+
  
  theme(text=element_text(family="arial",size=22))+
    scale_color_manual(labels=c("Atlantic","Pacific"),name="Ocean", values=c('red','blue'))+
    scale_fill_manual(labels=c("Atlantic","Pacific"),name="Ocean", values=c('red','blue'))+
  geom_smooth(method='lm',se=F,color="black")+scale_shape_manual(labels=c("Atlantic","Pacific"),name="Ocean",values=c(16,17))

##mean for comparison

brkptym3<-(lm(brkpty~mean,brkpts))
summary(brkptym3) 

ggplot(brkpts,aes(x=seasonlength10,y=brkpty))+
  geom_point(size=3,aes(color=oce,shape=oce))+theme_classic()+
  ylab("Maximal Growth (mm)")+
  xlab("Season Length (days), 10°C")+
  theme(text=element_text(family="arial",size=22))+
    scale_color_manual(labels=c("Atlantic","Pacific"),name="Ocean", values=c('red','blue'))+
    scale_fill_manual(labels=c("Atlantic","Pacific"),name="Ocean", values=c('red','blue'))+
  geom_smooth(method='lm',se=F,color="black")+scale_shape_manual(labels=c("Atlantic","Pacific"),name="Ocean",values=c(16,17))
```


When we look at season length when calculated at 10C, we see a significant relationship between maximal trait performance and season length. This trend becomes less signficant when we calculate it at 12.5C, mostly because our Pacific sites "ungroup" from the Atlantic sites. At 10C season length, we could be seeing possible countergradient variation! The one weird point in the Atlantic is Woods Hole. Anecdotal, I could attribute this to the very hot local conditions in the estuary, but can't say for sure. 

But what about the thermal optima?

### Thermal Optima (Breakpoint X axis), broken stick

```{r,include=T,echo=F,warning=F}




mods.brkx<-list(
  "nullo"=glm(brkptx~1,brkpts,family="gaussian"),
  "lat"=glm(brkptx~lat,brkpts,family="gaussian"),
  "mean"=glm(brkptx~mean,brkpts,family="gaussian"),
  "s.mean"=glm(brkptx~s.mean,brkpts,family="gaussian"),
  "q.mean"=glm(brkptx~q.mean,brkpts,family="gaussian"),
  "t.mean"=glm(brkptx~t.mean,brkpts,family="gaussian"),
  "seasonlength10"=glm(brkptx~seasonlength10,brkpts,family="gaussian"),
  "seasonlength12"=glm(brkptx~seasonlength12,brkpts,family="gaussian"),
  "omax"=glm(brkptx~max,brkpts,family="gaussian"),
  "spring"=glm(brkptx~spring,brkpts,family="gaussian"),
  "spring2"=glm(brkptx~spring2,brkpts,family="gaussian")
  )

aictab(mods.brkx)

brkptym<-lm(brkptx~spring2,brkpts)
summary(brkptym)

ggplot(brkpts,aes(x=spring2,y=brkptx))+
  geom_point(size=3,aes(color=oce,shape=oce))+geom_smooth(method="lm",se=F,color="black")+theme_classic()+
  ylab("Thermal Optima (°C)")+
  xlab("Maximum Spawning Period Mean (°C)")+
  theme(text=element_text(family="arial",size=22))+
  scale_color_manual(labels=c("Atlantic","Pacific"),name="Ocean", values=c('red','blue'))+
  scale_fill_manual(labels=c("Atlantic","Pacific"),name="Ocean", values=c('red','blue'))+
  scale_shape_manual(labels=c("Atlantic","Pacific"),name="Ocean",values=c(16,17))+scale_y_continuous(breaks=seq(20,30,2))+
  expand_limits(y=c(20,30))+scale_x_continuous(limits=c(14,26),breaks=seq(14,26,by=2))
                                                                                                   
  
#is mean multicollinear with seasonlength?
testm<-lm(brkptx~seasonlength10+mean,brkpts)
car::vif(testm)

```


Here, mean tempeature is the best predictor. However, season length 10 is also well-supported, so for consistency sake I present season length 10. There is no signficant pattern between season length and thermal optima (none with mean temp either). I can attribute this insignicance mostly to the presence of the Woods Hole population. If we remove this, the trend becomes slightly more signficant. It is worth pointing out this point and that because of our observations, we could attribute this outlier to other environmental effects, although I don't think we can actually eliminate it from analysis. 

#### Sensitivity analysis

Woods Hole seems to be an outlier for this pattern of decreasing thermal optima with season length. This is possibly due to very local-level effects of where we collected the woods hole population. what would happen if we remove it?

```{r,include=T,echo=F,warning=F}

#sensitivity analysis - exclude woods hole
brkpts_wh<-filter(brkpts,pop!="Woods Hole")

mods.brkx2<-list(
  "nullo"=glm(brkptx~1,brkpts_wh,family="gaussian"),
  "lato"=glm(brkptx~lat+oce,brkpts_wh,family="gaussian"),
  "meano"=glm(brkptx~mean+oce,brkpts_wh,family="gaussian"),
  "s.meano"=glm(brkptx~s.mean+oce,brkpts_wh,family="gaussian"),
  "q.meano"=glm(brkptx~q.mean+oce,brkpts_wh,family="gaussian"),
  "t.meano"=glm(brkptx~t.mean+oce,brkpts_wh,family="gaussian"),
  "seasonlengtho10"=glm(brkptx~seasonlength10+oce,brkpts_wh,family="gaussian"),
  "seasonlengtho16"=glm(brkptx~seasonlength12+oce,brkpts_wh,family="gaussian"),
  "maxo"=glm(brkptx~max+oce,brkpts_wh,family="gaussian"),
  "lat"=glm(brkptx~lat,brkpts_wh,family="gaussian"),
  "mean"=glm(brkptx~mean,brkpts_wh,family="gaussian"),
  "s.mean"=glm(brkptx~s.mean,brkpts_wh,family="gaussian"),
  "q.mean"=glm(brkptx~q.mean,brkpts_wh,family="gaussian"),
  "t.mean"=glm(brkptx~t.mean,brkpts_wh,family="gaussian"),
  "seasonlength10"=glm(brkptx~seasonlength10,brkpts_wh,family="gaussian"),
  "seasonlength12"=glm(brkptx~seasonlength12,brkpts_wh,family="gaussian"),
  "omax"=glm(brkptx~max,brkpts_wh,family="gaussian"),
  "o*lat"=glm(brkptx~lat*oce,brkpts_wh,family="gaussian"),
  "o*mean"=glm(brkptx~mean*oce,brkpts_wh,family="gaussian"),
  "o*s.mean"=glm(brkptx~s.mean*oce,brkpts_wh,family="gaussian"),
  "o*q.mean"=glm(brkptx~q.mean*oce,brkpts_wh,family="gaussian"),
  "o*t.mean"=glm(brkptx~t.mean*oce,brkpts_wh,family="gaussian"),
  "o*seasonlength10"=glm(brkptx~seasonlength10*oce,brkpts_wh,family="gaussian"),
  "seasonlength12"=glm(brkptx~seasonlength12*oce,brkpts_wh,family="gaussian"),
  "o*max"=glm(brkptx~max*oce,brkpts_wh,family="gaussian")
  )

aictab(mods.brkx2)

brkptym_wh<-lm(brkptx~seasonlength10,brkpts_wh)
summary(brkptym_wh)

ggplot(brkpts_wh,aes(x=seasonlength10,y=brkptx))+
  geom_point(size=3,aes(color=oce))+geom_smooth(method="lm",se=F,color="black")+theme_classic()+
  ylab("Thermal Optima")+
  xlab("Season Length (10c)")+
  theme(text=element_text(family="arial",size=22))+
  scale_color_manual(labels=c("Atlantic","Pacific"),name="Ocean", values=c('red','blue'))+
  scale_fill_manual(labels=c("Atlantic","Pacific"),name="Ocean", values=c('red','blue'))

```

With Woods Hole dropped, we see a better indication of a negative relationship between season length and optima. We probably can't justify droppping Woods Hole, but this is good to know. 

## Quadratic

One reason we are checking quadratic is that sometimes the optima isn't the optima! If you closely examine the segmented regressions, you see that in some cases the second segment's slope does not appear to be negative. Instead, it plateaus. This raises the question whether we can really define our breakpoint as optima. Potentially, we could interpret the breakpoints as the lowest temperature of maximum growth. At any rate, one idea is to redo all the analysis we just did for segmented regression but with a quadratic model, and seeing if we get a similar result in both the stacking but also the trends of the maximal growth and optima as we did with the segmented regression. 

```{r,include=T,echo=F,warning=F}
growth.alive<-na.omit(growth.alive)
#some quick exploratory stats on the quadratic model - can we assume normality?
quadm<-(glm(cal.length~poly(growth.alive$temp,2)+pop,growth.alive,family="gaussian"))
hist(resid(quadm))
plot(quadm)
#we will say yes

growth.alive$quad<-poly(growth.alive$temp,2)
bf<-filter(growth.alive,pop=="Beaufort")
fb<-filter(growth.alive,pop=="Folly Beach")
gb<-filter(growth.alive,pop=="Great Bay")
hm<-filter(growth.alive,pop=="Humboldt")
oy<-filter(growth.alive,pop=="Oyster")
sk<-filter(growth.alive,pop=="Skidaway")
wp<-filter(growth.alive,pop=="Willapa")
wh<-filter(growth.alive,pop=="Woods Hole")

growth.alive$temp<-na.omit(growth.alive$temp)

xminq<-min(poly(growth.alive$temp,2),na.rm=T)
xmaxq<-max(poly(growth.alive$temp,2),na.rm=T)

qmgb<-(lm(cal.length~poly(gb$temp,2,raw=T),gb))
cfgb<-coef(qmgb)
brkpts[3,16]<-(-cfgb[2]/(2*(cfgb[3])))
brkpts[3,17]<-cfgb[1]+cfgb[2]*brkpts[3,16]+cfgb[3]*(brkpts[3,16]^2)

qmwh<-(lm(cal.length~poly(wh$temp,2,raw=T),wh))
cfwh<-coef(qmwh)
brkpts[4,16]<-(-cfwh[2]/(2*(cfwh[3])))
brkpts[4,17]<-cfwh[1]+cfwh[2]*brkpts[4,16]+cfwh[3]*(brkpts[4,16]^2)

qmoy<-(lm(cal.length~poly(oy$temp,2,raw=T),oy))
cfoy<-coef(qmoy)
brkpts[5,16]<-(-cfoy[2]/(2*(cfoy[3])))
brkpts[5,17]<-cfoy[1]+cfoy[2]*brkpts[5,16]+cfoy[3]*(brkpts[5,16]^2)

qmbf<-(lm(cal.length~poly(bf$temp,2,raw=T),bf))
cfbf<-coef(qmbf)
brkpts[6,16]<-(-cfbf[2]/(2*(cfbf[3])))
brkpts[6,17]<-cfbf[1]+cfbf[2]*brkpts[6,16]+cfbf[3]*(brkpts[6,16]^2)


qmfb<-(lm(cal.length~poly(fb$temp,2,raw=T),fb))
cffb<-coef(qmfb)
brkpts[7,16]<-(-cffb[2]/(2*(cffb[3])))
brkpts[7,17]<-cffb[1]+cffb[2]*brkpts[7,16]+cffb[3]*(brkpts[7,16]^2)

qmsk<-(lm(cal.length~poly(sk$temp,2,raw=T),sk))
cfsk<-coef(qmsk)
brkpts[8,16]<-(-cfsk[2]/(2*(cfsk[3])))
brkpts[8,17]<-cfsk[1]+cfsk[2]*brkpts[8,16]+cfsk[3]*(brkpts[8,16]^2)

qmwp<-(lm(cal.length~poly(wp$temp,2,raw=T),wp))
cfwp<-coef(qmwp)
brkpts[1,16]<-(-cfwp[2]/(2*(cfwp[3])))
brkpts[1,17]<-cfwp[1]+cfwp[2]*brkpts[1,16]+cfwp[3]*(brkpts[1,16]^2)

qmhm<-(lm(cal.length~poly(hm$temp,2,raw=T),hm))
cfhm<-coef(qmhm)
brkpts[2,16]<-(-cfhm[2]/(2*(cfhm[3])))
brkpts[2,17]<-cfhm[1]+cfhm[2]*brkpts[2,16]+cfhm[3]*(brkpts[2,16]^2)




ggplot(growth.alive,aes(y=cal.length,x=temp,group=pop,linetype=pop))+geom_smooth(method='lm',formula=y~poly(x,2),se=F,aes(color=pop,size=pop))+
theme_classic()+theme(legend.position = "none")+labs(y="Shell Length (mm)",x="Temperature (°C)")+scale_x_continuous(breaks=c(16,20,24,26,28,30))+
  scale_color_manual(values=c("dark violet","navy","forest green","gold","dark orange","tomato","dark violet","navy"),labels=c("Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"),name="population")+
  scale_linetype_manual(values=c(1,1,1,1,1,1,4,4),labels=c("Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"),name="population")+
  scale_size_manual(values=c(1.2,1.2,1.2,1.2,1.2,1.2,1.2,1.2),labels=c("Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"),name="Population")+facet_wrap(pop~.)+geom_point()+theme(text=element_text(family="arial",size=22))

ggplot(growth.alive,aes(y=cal.length,x=temp,group=pop,linetype=pop))+geom_smooth(method='lm',formula=y~poly(x,2),se=F,aes(color=pop,size=pop))+
theme_classic()+labs(y="Growth Rate (mm)",x="Temperature (°C)")+scale_x_continuous(breaks=c(16,20,24,26,28,30))+
  scale_color_manual(values=c("dark violet","navy","forest green","gold","dark orange","tomato","dark violet","navy"),labels=c("Great Bay, NH","Woods Hole, MA","Oyster, VA","Beaufort, NC","Folly Beach, SC","Skidaway, GA","Willapa, WA","Humboldt, CA"),name="Population")+
  scale_linetype_manual(values=c(1,1,1,1,1,1,4,4),labels=c("Great Bay, NH","Woods Hole, MA","Oyster, VA","Beaufort, NC","Folly Beach, SC","Skidaway, GA","Willapa, WA","Humboldt, CA"),name="Population")+
  scale_size_manual(values=c(1.2,1.2,1.2,1.2,1.2,1.2,1.2,1.2),labels=c("Great Bay, NH","Woods Hole, MA","Oyster, VA","Beaufort, NC","Folly Beach, SC","Skidaway, GA","Willapa, WA","Humboldt, CA"),name="Population")+theme(text=element_text(family="arial",size=22))




```
Here, we see more or less similar patterns of cold pops stacked on warm pops. How do the breakpoints stack up?

Before we extract quadratic breakpoints, let's line up segmented regression and quadratic regression and see if they look close. The curves do match up nicely, but the breakpoints will be different. 

```{r,warning=F,echo=F}
ggplot(all.length.pred,aes(x=temp,y=cal.length),group=pop)+geom_line(aes(group=pop,x=temp,y=cal.length,color=pop,linetype=pop,size=pop))+
  ylab("Shell Length (mm)")+xlab("Common Garden Temperature (°C)")+theme_classic()+
  scale_x_continuous(breaks=c(16,20,24,26,28,30))+
  scale_linetype_manual(values=c(1,1,1,1,1,1,2,2),labels=c("Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"),name="pop")+
  scale_size_manual(values=c(1.2,1.2,1.2,1.2,1.2,1.2,1.2,1.2),labels=c("Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"),name="pop")+
  scale_color_manual(values=c("dark violet","navy","forest green","gold","dark orange","tomato","dark violet","navy"),labels=c("Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"),name="pop")+theme(text=element_text(family="arial",size=22))+geom_point(data=growth.alive,aes(x=temp,y=cal.length,group=pop))+facet_wrap(pop~.)+theme(legend.position = "none")+geom_smooth(method='lm',formula=y~poly(x,2),se=F,aes(color=pop,size=pop))


```

### Thermal optima (X Breakpoint), Quadratic
```{R,echo=F,warning=F}

mods.brkyq<-list(
  "nullo"=glm(brkptyq~1,brkpts,family="gaussian"),
   "lat"=glm(brkptyq~lat,brkpts,family="gaussian"),
  "mean"=glm(brkptyq~mean,brkpts,family="gaussian"),
  "s.mean"=glm(brkptyq~s.mean,brkpts,family="gaussian"),
  "q.mean"=glm(brkptyq~q.mean,brkpts,family="gaussian"),
  "t.mean"=glm(brkptyq~t.mean,brkpts,family="gaussian"),
  "seasonlength10"=glm(brkptyq~seasonlength10,brkpts,family="gaussian"),
  "seasonlength12"=glm(brkptyq~seasonlength12,brkpts,family="gaussian"),
  "omax"=glm(brkptyq~max,brkpts,family="gaussian"),
  "spring"=glm(brkptyq~spring,brkpts,family="gaussian"),
  "spring2"=glm(brkptyq~spring2,brkpts,family="gaussian")

  )

aictab(mods.brkyq)
#mean is the most highly supported model this time. 

brkptxmq<-lm(brkptyq~spring,brkpts)
summary(brkptxmq)

ggplot(brkpts,aes(x=spring,y=brkptyq))+
  geom_point(size=3,aes(color=oce))+geom_smooth(method="lm",se=F,color="black")+theme_classic()+
  ylab("Thermal Optima")+
  xlab("Season Length (days), 10C")+
  theme(text=element_text(family="arial",size=22))+
  scale_color_manual(labels=c("Atlantic","Pacific"),name="Ocean", values=c('red','blue'))+
  scale_fill_manual(labels=c("Atlantic","Pacific"),name="Ocean", values=c('red','blue'))
```
This is not significant in the slightest. part of the issue is that the quadratic optima for Oyster site is near 34C. Very unlikely! This is likely due to the very small breakpoint change in Oyster that is interpreted by the quadratic as a single slope. Basically, nothing predicts it well

### Maximal trait performance (Y Breakpoint), Quadratic
```{r,echo=F,warning=F}
mods.brkxq<-list(
  "null"=glm(brkptxq~1,brkpts,family="gaussian"),
  "lat"=glm(brkptxq~lat,brkpts,family="gaussian"),
  "mean"=glm(brkptxq~mean,brkpts,family="gaussian"),
  "s.mean"=glm(brkptxq~s.mean,brkpts,family="gaussian"),
  "q.mean"=glm(brkptxq~q.mean,brkpts,family="gaussian"),
  "t.mean"=glm(brkptxq~t.mean,brkpts,family="gaussian"),
  "seasonlength10"=glm(brkptxq~seasonlength10,brkpts,family="gaussian"),
  "seasonlength12"=glm(brkptxq~seasonlength12,brkpts,family="gaussian"),
  "omax"=glm(brkptxq~max,brkpts,family="gaussian"),
  "spring"=glm(brkptxq~spring,brkpts,family="gaussian"),
  "spring2"=glm(brkptxq~spring2,brkpts,family="gaussian")
  )

aictab(mods.brkxq)

brkptxmq<-lm(brkptxq~spring,brkpts)
summary(brkptxmq)

ggplot(brkpts,aes(x=spring,y=brkptxq))+
  geom_point(size=3,aes(color=oce))+geom_smooth(method="lm",se=F,color="black")+theme_classic()+
  ylab("Maximal Growth rate (mm)")+
  xlab("Season Length (days,12C)")+
  theme(text=element_text(family="arial",size=22))+
  scale_color_manual(labels=c("Atlantic","Pacific"),name="Ocean", values=c('red','blue'))+
  scale_fill_manual(labels=c("Atlantic","Pacific"),name="Ocean", values=c('red','blue'))

```

Here, we see that the maxima growth rate pattern is more or less preserved. While we don't trust the quadratic estimates for the optima, I do trust that there is a pattern of increasing growth rate with higher latitude. This is evidence for countergradient variation in growth. We can confirm this by looking further at growth in weight as well as in consumption rate. 

Finally, let us compare the breakpoints we have extracted from segmented and quadratic regression. We want to know if we see significantly different results in methods, because if we do then we have to be careful about which once we select (seg v. quad). We see here that while thermal optima estimates differ significantly between quad and seg, they do not when estimating maximal trait performance. Importantly, the sign of both relationships is the same. Therefore, we can be confident that our conclusion of countergradient variation in maximal trait performance is correct. 

```{r,echo=F}
brkptnewx<-gather(brkpts, modeltypex, x, c(brkptx,brkptyq)) 
brkptnewy<-gather(brkpts,modeltypey,y,c(brkpty,brkptxq))

ggplot(brkptnewx,aes(x=seasonlength10,y=x,group=modeltypex,color=modeltypex))+geom_point()+theme_classic()+scale_color_manual(labels=c("Segmented","Quadratic"),name="Thermal Optima",values=c("red","blue"))+geom_smooth(method=lm,se=F)+theme(text=element_text(family="arial",size=22))+ylab("Thermal Optima")+xlab("Season Length (days), 10C")

ggplot(brkptnewy,aes(x=seasonlength10,y=y,group=modeltypey,color=modeltypey))+geom_point()+theme_classic()+scale_color_manual(labels=c("Segmented","Quadratic"),name="Maximal Trait Performance",values=c("red","blue"))+geom_smooth(method=lm,se=F)+theme(text=element_text(family="arial",size=22))+ylab("Maximal Trait Performance")+xlab("Season Length (days), 10C")

brkptnewx$pop<-as.character(brkptnewx$pop)
summary(lm(x~modeltypex,brkptnewx))

brkptnewy$pop<-as.character(brkptnewy$pop)
summary(lm(y~modeltypey,brkptnewy))
```


```{r,include=F}

#brkpts$pop<-unlist(brkpts$pop)
#write.csv(brkpts,"C:/Users/drewv/Documents/UMASS/data/length_brkpts.csv",row.names=F)
```


