---
title: "TPC Weight"
author: "Andrew Villeneuve"
date: "5/27/2020"
output: 
  word_document: default
  html_document: default
  pdf_document: default
---

# The Study - read first

For this part of the study, we measured the total growth in grams of juvenile Urosalpinx snails. We grew snails in tea strainers separated by population for 24 days in a common garden experiment. Nine replicates per population were distributed in six temperatures, with three groups of three subreplicates in each temperature/population treatment. Snails were given food ad libitum. At the end of 24 days, we weighed the snails. Note that we did not take initial weights due to the small size of hatchling snails. Therefore, weights are not standardized for the growth period. This is especially pertinent since we found signficant differences in initial caliper length between populations, and a high correlation between length and weight (see data explroation). Therefore, results should be taken with a grain of salt. From this growth data, we can create thermal performance curves (TPCs) for each population to show the growth response of Urosaplinx populations to a range of laboratory temperatures.

The analysis of these growth curves requires two steps: 

1) the creation of models that describe the curved TPC shape using segmented and quadratic models and

2) the extraction of breakpoints (thermal optima = x breakpoint, maximal trait performance = y optima) for each population's TPC and modeling which environmental factors best describe any patterns in these optima across populations. I do this across two methods - segmented and quadratic regression. We want to see if both methods give approximately the same results, and based on model outputs decide which method we should use.

These two steps are presented, separately, in the Data Analysis section. The organization of these analyses thusly:

* Broken stick regression - I create, analyze, and plot segmented regressions 
  * Breakpoint analysis, broken stick - I extract the thermal optima (x brkpt) and maximal trait performance (y brkpt) of each population's segmented regression

* Quadratic model - I create, analyze, and plot quadratic regressions. 
  * Breakpoint analysis, quadratic - I extract the thermal optima (x brkpt) and maximal trait performance (y brkpt) of each population's quadratic regression
  

# Metadata

* code

  * Unique code for each indiviudal snail, corresponding to population, temperature treatment. First digit = temperature (1=16,2=20,3=24,4=26, 5=28, 6=30), second digit =  site (1=Willapa, 2=Humboldt, 3=Great Bay, 4=Woods Hole, 5=Oyster, 6=Beaufort, 7=Folly Beach, 8=Skidaway), third digit = tupperware bin number (1-3), fourth digit = snail replicate (1-3)

* pop

  * Source population of each snail. See data table below for list of site abbreivations with site. 

* temp

  * Common garden temperature the snails were raised in for 24 days. Degrees C

* hatch

  * hatch date of each snail from it's egg case (m/dd/yyyy)

* exp.date

  * Date on which hatchling snails were placed in the common garden experiment. Not more then 2 days from the hatch date. (m/dd/yyyy)

* grow.date

  * End date where growth measurements were taken. 24 days after exp.date, therefore no more then 26 days post hatch (m/dd/yyyy)

* alive

  * Tracks if snails survived the experient. m marks missing, n marks no, y marks yes

* rem.oysters

  * Was there a surplus of food at the end of the experiment? n marks no, y marks yes

* cal.length.start

  * caliper length of hatchlings upon entering the experment. We took photos of snails before entering snails into the experiment, and then used ImageJ to extract snail sizes. Size in mm

* cal.length.end

  * caliper length of hatchling at the end of the experiemnt. We took caliper measurements of the snails, as well as verifying the measurements using a subset of photographs in ImageJ. Size in mm

* wt

  * End weight of snail. Note that no initial starting weight was recorded. Weight in g.

* ran.out

  * Did the snail ever run out of food during the consumption experiment? 1 for yes, 0 for no

* bin

  * Bin number, controls subreplication. The third digit of the code. 

* oce

  * Ocean (Atlantic or Pacific)

```{r,echo=F, warning=F}
data.frame("site abbreviation" = c("gbj","wh","oy","bf","fb","gcsk","nah1516","hmi2"), "site"=c("Great Bay, NH","Woods Hole, MA","Oyster, VA","Beaufort, NC","Folly Beach, SC","Skidaway, GA","Willapa, WA","Humboldt, CA"))


```

# Data setup
```{r setup, include=FALSE,echo=F}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(rmarkdown)
library(dplyr)
library(ggplot2)
library(forcats)
library(PerformanceAnalytics)
library(sjPlot)
library(lubridate)
library(HH)
library(AICcmodavg)
library(MuMIn)
library(segmented)
library(ggiraphExtra)
library(extrafont)
library(here)
library(lubridate)
library(tidyr)
loadfonts(device = "win")


growth<-read.csv(here::here("data/growth.csv"))
summary(growth)
which(growth$wt>0.09)
growth[92,12]=0.0109
growth[193,12]=.0151
growth[232,12]=.023
growth[268,12]=.0261

#Let's bring in the consumption data, and see which snails ran out of food MORE than once. We will keep snails that ran out only once. 

cons<-read.csv(here::here("data/uro.consumption2.csv"))
cons<-na.omit(cons)

cons$allcons<-ifelse(cons$all.consumed=="n","0",ifelse(cons$all.consumed=="y","1",NA))
cons$allcons<-as.numeric(cons$allcons)

consfilter<-cons%>%filter(all.consumed!="n")%>%group_by(TPC.Label)%>%dplyr::summarise(n=n())
consfilter$TPC.Label<-as.character(consfilter$TPC.Label)


#when did snails die, timepoint wise?
conscase<-cons%>%filter(all.consumed!="n")%>%group_by(timepoint)%>%dplyr::summarise(n=n())
conscase$n<-as.integer(conscase$n)



growth<-subset(growth,code!=(6212))

###eliminate snails that ever ran out of food
#growth<-subset(growth,code!=(6833)&code!=(6831)&code!=(6711)&code!=(6632)&code!=(6631)&code!=(6611)&code!=(6433)&code!=(6422)&code!=(6412)&code!=(6411)&code!=(6233)&code!=(6212)&code!=(6212)&code!=(6111)&code!=(5831)&code!=(5813)&code!=(5732)&code!=(5731)&code!=(5723)&code!=(5711)&code!=(5622)&code!=(5531)&code!=(5333)&code!=(5313)&code!=(5312)&code!=(5213)&code!=(5121)&code!=(5112)&code!=(4522)&code!=(4521)&code!=(4433)&code!=(4432)&code!=(4231)&code!=(3821)&code!=(3712)&code!=(3433)&code!=(3432)&code!=(3421)&code!=(3413)&code!=(2422)&code!=(2421))

#how many died? 37
dead<-growth%>%filter(alive=="n")%>%group_by(temp)%>%dplyr::summarise(n=n())

deadpop<-growth%>%filter(alive=="n")%>%group_by(pop)%>%dplyr::summarise(n=n())

#how many disappeared/unknown?
dis<-growth%>%filter(alive=="m")%>%dplyr::summarise(n=n())


growth<-growth[!(growth$alive=="n"),]

growth<-growth[!(growth$alive=="m"),]
growth.con<-growth[!(growth$ran.out=="1"),]
growth.con<-na.omit(growth.con)
growth<-na.omit(growth)


##temeperature data


gbj<-read.csv(here::here("data/environmental_data/rawAtlantic/atl/gbj.csv"),header=T)
gbj$rdate<-as.POSIXct(gbj$DateTimeStamp,tz="","%m/%d/%Y%H:%M")
gbj$oce<-"a"
wh<-read.csv(here::here("data/environmental_data/rawAtlantic/atl/wh.csv"),header=T)
wh$rdate<-as.POSIXct(wh$DateTimeStamp,tz="", "%m/%d/%Y%H:%M")
wh$oce<-"a"
oy<-read.csv(here::here("data/environmental_data/rawAtlantic/atl/oy.csv"),header=T)
oy$rdate<-as.POSIXct(oy$DateTimeStamp,tz="", "%m/%d/%Y%H:%M")
oy$oce<-"a"
bf<-read.csv(here::here("data/environmental_data/rawAtlantic/atl/bf.csv"),header=T)
bf$rdate<-as.POSIXct(bf$DateTimeStamp,tz="", "%m/%d/%Y%H:%M")
bf$oce<-"a"
fb<-read.csv(here::here("data/environmental_data/rawAtlantic/atl/fb.csv"),header=T)
fb$rdate<-as.POSIXct(fb$DateTimeStamp,tz="", "%m/%d/%Y%H:%M")
fb$oce<-"a"
gcsk<-read.csv(here::here("data/environmental_data/rawAtlantic/atl/gcsk.csv"),header=T)
gcsk$rdate<-as.POSIXct(gcsk$DateTimeStamp,tz="", "%m/%d/%Y%H:%M")
gcsk$oce<-"a"

nah1516<-read.csv(here::here("data/environmental_data/rawPacific/pac/nahcotta_2015_2016.csv"),header=T)#2015 through August, 2016 data after that
nah1516$rdate<-as.POSIXct(nah1516$DateTimeStamp,tz="", "%m/%d/%Y%H:%M")
nah1516$oce<-"p"
hmi2<-read.csv(here::here("data/environmental_data/rawPacific/pac/hmi2.csv"),header=T)
hmi2$rdate<-as.POSIXct(hmi2$DateTimeStamp,tz="", "%m/%d/%Y%H:%M")#Indian island 2015
hmi2$oce<-"p"
to3<-read.csv(here::here("data/environmental_data/rawPacific/pac/to3.csv"),header=T)
to3$rdate<-as.POSIXct(to3$DateTimeStamp,tz="","%m/%d/%Y%H:%M")##stitched 2014 and 2015 (post Nove. 21 data together)
to3$oce<-"p"

#create objects of tempreatures during summer only 
s.gbj<-filter(gbj,rdate>"2018-06-01 00:00:00" & rdate< "2018-09-30 00:00:00")
s.wh<-filter(wh,rdate>"2018-06-01 00:00:00" & rdate< "2018-09-30 00:00:00")
s.oy<-filter(oy,rdate>"2018-06-01 00:00:00" & rdate< "2018-09-30 00:00:00")
s.bf<-filter(bf,rdate>"2018-06-01 00:00:00" & rdate< "2018-09-30 00:00:00")
s.fb<-filter(fb,rdate>"2018-06-01 00:00:00" & rdate< "2018-09-30 00:00:00")
s.to3<-filter(to3,rdate>"2018-06-01 00:00:00" & rdate< "2018-09-30 00:00:00")
s.hmi2<-filter(hmi2,rdate>"2018-06-01 00:00:00" & rdate< "2018-09-30 00:00:00")
s.nah1516<-filter(nah1516,rdate>"2018-06-01 00:00:00" & rdate< "2018-09-30 00:00:00")
s.gcsk<-filter(gcsk,rdate>"2018-06-01 00:00:00" & rdate< "2018-09-30 00:00:00")

##Quartiles
q<-data.frame("site" = c("gbj","wh","oy","bf","fb","nah1516","hmi2","to3","gcsk"),"quantile"=NA,"decile"=NA, "max"=NA, "mean"=NA,"summer mean"=NA,"seasonlength10"=NA,"seasonlength16"=NA)
q[1,2]<-quantile(s.gbj$WTMP,0.75,type=1)
q[2,2]<-quantile(s.wh$WTMP,0.75,type=1)
q[3,2]<-quantile(s.oy$WTMP,0.75,type=1)
q[4,2]<-quantile(s.bf$WTMP,0.75,type=1)
q[5,2]<-quantile(s.fb$WTMP,0.75,type=1)
q[6,2]<-quantile(s.nah1516$WTMP,0.75,type=1)
q[7,2]<-quantile(s.hmi2$WTMP,0.75,type=1)
q[8,2]<-quantile(s.to3$WTMP,0.75,type=1)
q[9,2]<-quantile(s.gcsk$WTMP,0.75,type=1)

#upper 90th
q[1,3]<-quantile(s.gbj$WTMP,0.9,type=1)
q[2,3]<-quantile(s.wh$WTMP,0.9,type=1)
q[3,3]<-quantile(s.oy$WTMP,0.9,type=1)
q[4,3]<-quantile(s.bf$WTMP,0.9,type=1)
q[5,3]<-quantile(s.fb$WTMP,0.9,type=1)
q[6,3]<-quantile(s.nah1516$WTMP,0.9,type=1)
q[7,3]<-quantile(s.hmi2$WTMP,0.9,type=1)
q[8,3]<-quantile(s.to3$WTMP,0.9,type=1)
q[9,3]<-quantile(s.gcsk$WTMP,0.9,type=1)

#maximum temperature
q[1,4]<-s.gbj %>%  summarise(Value = max(WTMP))
q[2,4]<-s.wh  %>% summarise(Value = max(WTMP))
q[3,4]<-s.oy  %>% summarise(Value = max(WTMP))
q[4,4]<-s.bf  %>% summarise(Value = max(WTMP))
q[5,4]<-s.fb  %>% summarise(Value = max(WTMP))
q[6,4]<-s.nah1516 %>% summarise(Value = max(WTMP))
q[7,4]<-s.hmi2  %>% summarise(Value = max(WTMP))
q[8,4]<-s.to3  %>% summarise(Value = max(WTMP))
q[9,4]<-s.gcsk  %>% summarise(Value=max(WTMP))

#means
q[1,5]<-mean(gbj$WTMP)
q[2,5]<-mean(wh$WTMP)
q[3,5]<-mean(oy$WTMP)
q[4,5]<-mean(bf$WTMP)
q[5,5]<-mean(fb$WTMP)
q[6,5]<-mean(nah1516$WTMP)
q[7,5]<-mean(hmi2$WTMP)
q[8,5]<-mean(to3$WTMP)
q[9,5]<-mean(gcsk$WTMP)

#summer means
#means
q[1,6]<-mean(s.gbj$WTMP)
q[2,6]<-mean(s.wh$WTMP)
q[3,6]<-mean(s.oy$WTMP)
q[4,6]<-mean(s.bf$WTMP)
q[5,6]<-mean(s.fb$WTMP)
q[6,6]<-mean(s.nah1516$WTMP)
q[7,6]<-mean(s.hmi2$WTMP)
q[8,6]<-mean(s.to3$WTMP)
q[9,6]<-mean(s.gcsk$WTMP)

#season length

q[1,8]<-gbj%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>16)%>%tally
q[2,8]<-wh%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>16)%>%tally
q[3,8]<-oy%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>16)%>%tally
q[4,8]<-bf%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>16)%>%tally
q[5,8]<-fb%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>16)%>%tally
q[6,8]<-nah1516%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>16)%>%tally
q[7,8]<-hmi2%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>16)%>%tally
q[8,8]<-to3%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>16)%>%tally
q[9,8]<-gcsk%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>16)%>%tally

q[1,7]<-gbj%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>10)%>%tally
q[2,7]<-wh%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>10)%>%tally
q[3,7]<-oy%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>10)%>%tally
q[4,7]<-bf%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>10)%>%tally
q[5,7]<-fb%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>10)%>%tally
q[6,7]<-nah1516%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>10)%>%tally
q[7,7]<-hmi2%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>10)%>%tally
q[8,7]<-to3%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>10)%>%tally
q[9,7]<-gcsk%>%mutate(day=as.Date(rdate,format="%Y-%m-%d"))%>%group_by(day)%>%dplyr::summarise(daily_wtmp=mean(WTMP))%>%na.omit()%>%filter(daily_wtmp>10)%>%tally


pac2<-rbind(hmi2,nah1516)
atll<-rbind(gcsk,fb,bf,oy,wh,gbj)

temp<-rbind(pac2,atll) #temperature data for all

means<-data.frame(with(temp,tapply(WTMP,site,mean)))

#summer means

summer.temp<-filter(temp,rdate>"2018-06-01 00:00:00" & rdate< "2018-09-30 00:00:00")
s.mean<-data.frame(with(summer.temp,tapply(WTMP,site,mean)))

temp$date<-as.Date(temp$rdate)

temp$site<-factor(temp$site, levels=c("gbj","wh","oy","bf","fb","GCSK","nah15","hmi2"))
#"Great Bay, NH","Woods Hole, MA","Oyster, VA","Beaufort, NC","Folly Beach, SC","Skidaway, GA","Willapa, WA","Humboldt, CA"
```





We had to clean parts of the data to prepare it for analysis. The first issue we had to resolve was the extreme weight and caliper length outliers, which was clearly due to a misplaced decimal or missing 0 during data entry (these data points were off by a factor of 10 from "correct" data). In the silenced part of the markdown, this had to be corrected 5/432 times. 

The second issue was that some snails ran out of food during the growth experiment, which could jeopardize our assumption of unlimited growth while in the common garden experiment. We checked snail consumption three times over the course of the experiment, both to ensure snails had food but also to record which ones ran out of food. The vast majority (391/432) of snails never ran out of food. 40/432 ran out of food once, while 1/432 ran out of food twice. The plot below shows this breakdown, with snails that never ran out food removed. For the purposes of this experiment, we decided to include snails that missed a single meal during the entirity of the experiment, but removed the single case in which a snail ran out of food twice. 

Further, the second plot below shows that most snails consumed all their food at timepoint 1, followed by timepoint 2 and finally timepoint 3 (seven snails ran out at t3)

```{r,echo=F}

ggplot(consfilter,aes(x=TPC.Label,y=n,group=TPC.Label))+geom_bar(stat="identity")+labs(x="Unique snail code",y="Number of times ran out of food")
ggplot(conscase,aes(x=timepoint,y=n,group=timepoint))+geom_bar(stat="identity")


```


The third issue was that some snails died, or went missing, over the course of the experiment. 37 snails died, and 1 went missing. We removed these snails from consideration, as we could not get a final growth measurement. The two plots below show the distribution of dead snails across site and temperature. Intriguingly, snails tended to died at lower temperatures, especially at 16C. We will see later on this was the temperature of lowest growth as well. 

```{r,echo=F}
ggplot(dead,aes(x=temp,y=n))+geom_bar(stat="identity")+labs(x="Common Garden Temperature",y="Mortalities (n)")

ggplot(deadpop,aes(x=pop,y=n))+geom_bar(stat="identity")+labs(x="Population",y="Mortalities (n)")

```

In, between removing snails that ran out of food twice (n=1), died (n=37), or went missing (n=1), there were 393 snails whos growth rates we kept. 

## Environmental Data

We extracted temperature data from each site. With this data, we calculated different environmental predictors that might explain patterns in growth. 

* "Quantile" (°C)  
  *The average SST of the upper 75th percentile of summer months (06/01/2018 - 09/30/2018)
* "Decile" (°C)
  *The average SST of the upper 90th percentile of summer months (06/01/2018 - 09/30/2018)
* "max" 
  *The maximum SST value recorded during summer months (06/01/2018 - 09/30/2018)
* "mean"  (°C)
  *The mean SST of the site, calculated across the entire year
* "summer mean" (°C)
  *The mean SST of the site, calculated during the summer months (06/01/2018 - 09/30/2018)
* "seasonlength10/16" (days)
  *The number of days where the average daily temperature exceeded a threshold. Here, we use 16C, since this was our lowest temperature in experimentation and resulted in very slow growth (accelerates at 20C) - from Cheng et al. 2017. However, things become signicant when performed at 10C. We can also use 12.5C and get somewhat significant results, after the breakpoint for Oxygen consumption found in Schick's dissertation (Schick 1971) 

We also used latitude as a predictor (not shown in table below)

```{r,include=T,echo=F,warning=F}
#plot of site temperatures
ggplot(data=temp,aes(x=date,y=WTMP,color=site))+scale_color_viridis_d(name="Site",labels=c("Great Bay, NH","Woods Hole, MA","Oyster, VA","Beaufort, NC","Folly Beach, SC","Skidaway, GA","Willapa, WA","Humboldt, CA"),option="D")+theme_classic()+geom_vline(xintercept = 152)+geom_vline(xintercept = 273)+ylab("SST (°C)")+xlab("")+scale_fill_discrete(name="Site",labels=c("Great Bay, NH","Woods Hole, MA","Oyster, VA","Beaufort, NC","Folly Beach, SC","Skidaway, GA","Willapa, WA","Humboldt, CA"))+scale_x_date(date_labels = "%b")+theme(text=element_text(family="sanserif",size=14))+stat_smooth(se=F,size=2)+geom_point(alpha=0.0002,color="black",fill="white")+guides(color=guide_legend(override.aes=list(fill=NA)))
  
q


```

# Data Exploration

## Do weights differ between populations

Do populations differ in their weight? Here, ANOVA tells us that growth between sites are signficantly different
```{r,include=T,echo=F,warning=F}

anovawt<-(aov(wt~pop*temp,data=growth))
summary(anovawt)
growth$pop<-as.factor(growth$pop)

```

## Full model residuals

How do the residuals of a full model look? Here, they look acceptable. 

```{r}
weight.model<-glm(wt~pop*temp*oce*bin*ran.out,growth,family=gaussian)
plot(weight.model)
hist(resid(weight.model),breaks=20)

skewness(growth$wt)

```


## Do sites differ? 

Do populations differ in their final weight across the common garden experiemnt? Here, ANOVA tells us that growth between sites are signficantly different. We are justified in pursuing population and temperature level differences. 
```{r,include=T,warning=F}

anovasites<-(aov(wt~pop*temp,data=growth))
summary(anovasites)
growth$pop<-as.factor(growth$pop)


```


## Correlations
```{r,include=T,echo=F,warning=F}
M <- (growth[,9:12])
chart.Correlation(M,histogram=TRUE)

```

Here, we see that cal length and weight are both highly correlated. Since we had previously found initial caliper length to be different between populations (see uro growth rate length markdown), we must keep this in mind when interpreting any results. 


## Coplots

Other than temperature and population, which we control for, do we see different reactions depending on tupperware bin (our subreplication)? Here, reactions appaer to be the same no matter what bin we used. We do not need to include bin in our models (further supported by AIC below in data analysis). Note: Margins were too big on this figure to include in the markdown - viewable in R console. 
```{r,echo=F}
#dev.off()
#coplot(wt~temp |pop*bin,data=growth)

```
# Data Analysis

## Broken Stick regression

It's hard to compare TPC against one another. One method we've settled on is the use of broken stick regression to allow us to quantify the shape of the reaction as well as the thermal optima (x) and the maximal trait performance (y). Here, we used the segmented package to create single-optima broken stick regressions that also allow us to extract optimas.

We used a separate model for each population, as segmented does not allow for grouping. We used the following formulation: glm(weight ~ temperature, population,family=gaussian), such that we modeled the response of shell lengths from a single population to temperature.
```{r,echo=F,warning=F}
bf<-filter(growth, pop=="Beaufort")
fb<-filter(growth,pop=="Folly Beach")
gb<-filter(growth,pop=="Great Bay")
hm<-filter(growth,pop=="Humboldt")
oy<-filter(growth,pop=="Oyster")
sk<-filter(growth,pop=="Skidaway")
wp<-filter(growth,pop=="Willapa")
wh<-filter(growth,pop=="Woods Hole")

m1.2<-glm(wt~temp*pop,growth,family=gaussian)
#"pop*temp" is the best model

##Extract residuals
hist(resid(m1.2),main="",xlab="residuals")

growth<-na.omit(growth)
plot(resid(m1.2)~growth$temp)
#resids for temperatures look a little wonky.
plot(resid(m1.2)~growth$pop)

m.gb<-glm(wt~temp,gb,family=gaussian)
seg.gb<-segmented(m.gb,seg.z = ~temp, psi=24)

m.wh<-glm(wt~temp,wh,family=gaussian)
seg.wh<-segmented(m.wh,seg.z = ~temp, psi=24)

m.oy<-glm(wt~temp,oy,family=gaussian)
seg.oy<-segmented(m.oy,seg.Z = ~temp, psi=26,seg.control(maxit.glm=100),fix.npsi=T,n.boot=500)

m.bf<-glm(wt~temp,bf,family=gaussian)
seg.bf<-segmented(m.bf,seg.Z = ~temp, psi=24)

m.fb<-glm(wt~temp,fb,family=gaussian)
seg.fb<-segmented(m.fb,seg.Z = ~temp, psi=26)

m.sk<-glm(wt~temp,sk,family=gaussian)
seg.sk<-segmented(m.sk,seg.Z = ~temp, psi=24)

m.hm<-glm(wt~temp,hm,family=gaussian)
seg.hm<-segmented(m.hm,seg.Z = ~temp, psi=26)

m.wp<-glm(wt~temp,wp,family=gaussian)
seg.wp<-segmented(m.wp,seg.Z = ~temp, psi=26)

xmin<-min(growth$temp,na.rm=T)
xmax<-max(growth$temp,na.rm=T)

##plotting predicted values
predicted.gb<-data.frame(temp=seq(xmin,xmax,length.out=100))
predicted.gb$wt<-predict(seg.gb,predicted.gb)
predicted.gb$pop<-"gb"
predicted.gb$oce<-"a"

predicted.wh<-data.frame(temp=seq(xmin,xmax,length.out=100))
predicted.wh$wt<-predict(seg.wh,predicted.wh)
predicted.wh$pop<-"wh"
predicted.wh$oce<-"a"

predicted.oy<-data.frame(temp=seq(xmin,xmax,length.out=100))
predicted.oy$wt<-predict(seg.oy,predicted.oy)
predicted.oy$pop<-"oy"
predicted.oy$oce<-"a"

predicted.bf<-data.frame(temp=seq(xmin,xmax,length.out=100))
predicted.bf$wt<-predict(seg.bf,predicted.bf)
predicted.bf$pop<-"bf"
predicted.bf$oce<-"a"

predicted.fb<-data.frame(temp=seq(xmin,xmax,length.out=100))
predicted.fb$wt<-predict(seg.fb,predicted.fb)
predicted.fb$pop<-"fb"
predicted.fb$oce<-"a"

predicted.sk<-data.frame(temp=seq(xmin,xmax,length.out=100))
predicted.sk$wt<-predict(seg.sk,predicted.sk)
predicted.sk$pop<-"sk"
predicted.sk$oce<-"a"

predicted.wp<-data.frame(temp=seq(xmin,xmax,length.out=100))
predicted.wp$wt<-predict(seg.wp,predicted.wp)
predicted.wp$pop<-"wp"
predicted.wp$oce<-"p"


predicted.hm<-data.frame(temp=seq(xmin,xmax,length.out=100))
predicted.hm$wt<-predict(seg.hm,predicted.hm)
predicted.hm$pop<-"hm"
predicted.hm$oce<-"p"

all.pred<-rbind(predicted.gb,predicted.wh,predicted.oy,predicted.bf,predicted.fb,predicted.sk,predicted.wp,predicted.hm)

all.pred$pop<-factor(all.pred$pop,levels=c("gb","wh","oy","bf","fb","sk","wp","hm"))
all.pred$size<-1
all.pred$population<-ifelse(all.pred$pop=="gb","Great Bay",ifelse(all.pred$pop=="wh","Woods Hole",ifelse(all.pred$pop=="oy","Oyster",ifelse(all.pred$pop=="bf","Beaufort",ifelse(all.pred$pop=="fb","Folly Beach",ifelse(all.pred$pop=="sk","Skidaway",ifelse(all.pred$pop=="wp","Willapa",ifelse(all.pred$pop=="hm","Humboldt",NA))))))))
all.pred$population<-as.factor(all.pred$population)
all.pred$population<-factor(all.pred$population,levels=c("Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"))


growth$population<-growth$pop
growth$population<-factor(growth$pop,levels=c("Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"))

ggplot(all.pred,aes(x=temp,y=wt,group=pop))+geom_line(aes(x=temp,y=wt,color=pop,linetype=pop,size=pop))+
  ylab("Weight(g)")+xlab("Common Garden Temperature")+theme_classic()+
  scale_y_continuous(breaks=c(0.005,0.01,0.015,0.02,0.025))+scale_x_continuous(breaks=c(16,20,24,26,28,30))+
  scale_linetype_manual(values=c(1,1,1,1,1,1,3,3),labels=c("Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"),name="Population")+
  scale_size_manual(values=c(1.2,1.2,1.2,1.2,1.2,1.2,1.2,1.2),labels=c("Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"),name="Population")+
  scale_color_manual(values=c("dark violet","navy","forest green","gold","dark orange","tomato","dark violet","navy"),labels=c("Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"),name="Population")+theme(text=element_text(family="arial",size=22))

ggplot(all.pred,aes(x=temp,y=wt,group=population))+geom_line(aes(x=temp,y=wt,color=population,linetype=population,size=population))+
  ylab("Weight(g)")+xlab("Common Garden Temperature")+theme_classic()+
  scale_y_continuous(breaks=c(0.005,0.01,0.015,0.02,0.025))+scale_x_continuous(breaks=c(16,20,24,26,28,30))+
  scale_linetype_manual(values=c(1,1,1,1,1,1,3,3),labels=c("Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"),name="population")+
  scale_size_manual(values=c(1.2,1.2,1.2,1.2,1.2,1.2,1.2,1.2),labels=c("Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"),name="population")+
  scale_color_manual(values=c("dark violet","navy","forest green","gold","dark orange","tomato","dark violet","navy"),labels=c("Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"),name="population")+
  geom_point(data=growth,aes(x=temp,y=wt,group=population))+facet_wrap(population~.)+theme(legend.position = "none")+theme(text=element_text(family="arial",size=22))

```

Here, we see that the stacking of regressions is not as clear as with shell length (separate markdown). To see if countergradient variation in still present, we will have to extract breakpoints. First off, how confident are we in our breakpoints?

*P-score: The P-score tests the null hypothesis for no difference in slopes, i.e. no breakpoint. If P is below 0.05, then there is a breakpoint. We see here that not all P-scores are signficant, and therefore we fail to reject the null hypothesis of no change in slope, ie there are no breakpoints
 
* Davies test: we perform this analysis, but is less powerful for one breakpoint analyses. I am not certain what this means, since the null hypothesis is no breakpoint but we get radically different results this way.
 
*  CI Low/High: Confidence interval of the breakpoint
 
* Breakpoint: Breakpoint
 
 
```{r,echo=F,warning=F}
scoreswt<-data.frame("site" = c("Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"),"P Score"=NA,"Davies Test"=NA,"CI Low"=NA,"CI High"=NA,"breakpoint"=NA)
scoreswt[1,2]<-pscore.test(seg.gb,~temp)[[5]]
scoreswt[2,2]<-pscore.test(seg.wh,~temp)[[5]]
scoreswt[3,2]<-pscore.test(seg.oy,~temp)[[5]]
scoreswt[4,2]<-pscore.test(seg.bf,~temp)[[5]]
scoreswt[5,2]<-pscore.test(seg.fb,~temp)[[5]]
scoreswt[6,2]<-pscore.test(seg.sk,~temp)[[5]]
scoreswt[7,2]<-pscore.test(seg.wp,~temp)[[5]]
scoreswt[8,2]<-pscore.test(seg.hm,~temp)[[5]]

scoreswt[1,3]<-davies.test(seg.gb,~temp)[[5]]
scoreswt[2,3]<-davies.test(seg.wh,~temp)[[5]]
scoreswt[3,3]<-davies.test(seg.oy,~temp)[[5]]
scoreswt[4,3]<-davies.test(seg.bf,~temp)[[5]]
scoreswt[5,3]<-davies.test(seg.fb,~temp)[[5]]
scoreswt[6,3]<-davies.test(seg.sk,~temp)[[5]]
scoreswt[7,3]<-davies.test(seg.wp,~temp)[[5]]
scoreswt[8,3]<-davies.test(seg.hm,~temp)[[5]]

scoreswt[1,4]<-confint(seg.gb)[[2]]
scoreswt[2,4]<-confint(seg.wh)[[2]]
scoreswt[3,4]<-confint(seg.oy)[[2]]
scoreswt[4,4]<-confint(seg.bf)[[2]]
scoreswt[5,4]<-confint(seg.fb)[[2]]
scoreswt[6,4]<-confint(seg.sk)[[2]]
scoreswt[7,4]<-confint(seg.wp)[[2]]
scoreswt[8,4]<-confint(seg.hm)[[2]]

scoreswt[1,5]<-confint(seg.gb)[[3]]
scoreswt[2,5]<-confint(seg.wh)[[3]]
scoreswt[3,5]<-confint(seg.oy)[[3]]
scoreswt[4,5]<-confint(seg.bf)[[3]]
scoreswt[5,5]<-confint(seg.fb)[[3]]
scoreswt[6,5]<-confint(seg.sk)[[3]]
scoreswt[7,5]<-confint(seg.wp)[[3]]
scoreswt[8,5]<-confint(seg.hm)[[3]]

scoreswt[1,6]<-confint(seg.gb)[[1]]
scoreswt[2,6]<-confint(seg.wh)[[1]]
scoreswt[3,6]<-confint(seg.oy)[[1]]
scoreswt[4,6]<-confint(seg.bf)[[1]]
scoreswt[5,6]<-confint(seg.fb)[[1]]
scoreswt[6,6]<-confint(seg.sk)[[1]]
scoreswt[7,6]<-confint(seg.wp)[[1]]
scoreswt[8,6]<-confint(seg.hm)[[1]]


scoreswt
```

Through these tests, my trust in the accuracy of the breakpoints on the x axis is low. I will remember this as I go through breakpoint analysis

## Breakpoints analysis 


To be able to complete statistical analysis of the differences in TPC curves, I extracted the x and y componenets of each curve to give me the thermal optima and maximal trait performance, respectively. This extraction is silenced in code. Once we have extracted the thermal optima and maximal trait performance, we can move on to the relationship between environment and each breakpoint component. 

```{r,include=F}
brkpts<-data.frame(matrix(,nrow=8,ncol=15))
colnames(brkpts)<-c("pop","brkptx","brkpty","lat","mean","s.mean","q.mean","t.mean","oce","ratio","brkptxq","brkptyq","max","seasonlength10","seasonlength16")

brkpts$pop<-list("Willapa","Humboldt","Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway")

brkpts[1,2]<-seg.wp$psi[[2]]
brkpts[2,2]<-seg.hm$psi[[2]]
brkpts[3,2]<-seg.gb$psi[[2]]
brkpts[4,2]<-seg.wh$psi[[2]]
brkpts[5,2]<-seg.oy$psi[[2]]
brkpts[6,2]<-seg.bf$psi[[2]]
brkpts[7,2]<-seg.fb$psi[[2]]
brkpts[8,2]<-seg.sk$psi[[2]]

brkpts[1,3]<-(seg.wp$psi[[2]]*coef(seg.wp)[[2]])+(coef(seg.wp)[[1]])
brkpts[2,3]<-(seg.hm$psi[[2]]*coef(seg.hm)[[2]])+(coef(seg.hm)[[1]])
brkpts[3,3]<-(seg.gb$psi[[2]]*coef(seg.gb)[[2]])+(coef(seg.gb)[[1]])
brkpts[4,3]<-(seg.wh$psi[[2]]*coef(seg.wh)[[2]])+(coef(seg.wh)[[1]])
brkpts[5,3]<-(seg.oy$psi[[2]]*coef(seg.oy)[[2]])+(coef(seg.oy)[[1]])
brkpts[6,3]<-(seg.bf$psi[[2]]*coef(seg.bf)[[2]])+(coef(seg.bf)[[1]])
brkpts[7,3]<-(seg.fb$psi[[2]]*coef(seg.fb)[[2]])+(coef(seg.fb)[[1]])
brkpts[8,3]<-(seg.sk$psi[[2]]*coef(seg.sk)[[2]])+(coef(seg.sk)[[1]])

#lat
brkpts$lat<-ifelse(brkpts$pop=="Beaufort",34.819,ifelse(brkpts$pop=="Folly Beach",32.660525, ifelse(brkpts$pop=="Great Bay",43.089589,ifelse(brkpts$pop=="Humboldt",40.849448,ifelse(brkpts$pop=="Oyster", 37.288562,ifelse(brkpts$pop=="Tomales",38.12805,ifelse(brkpts$pop=="Woods Hole",41.57687,ifelse(brkpts$pop=="Willapa",46.5007,ifelse(brkpts$pop=="Skidaway",31.970,NA)))))))))                                                                                                                                                                                                                                                                                   

#means
brkpts[2,5]<-means[1,1]
brkpts[8,5]<-means[3,1]
brkpts[6,5]<-means[5,1]
brkpts[3,5]<-means[8,1]
brkpts[4,5]<-means[7,1]
brkpts[5,5]<-means[6,1]
brkpts[1,5]<-means[2,1]
brkpts[7,5]<-means[4,1]

#s.mean
brkpts[2,6]<-s.mean[1,1]
brkpts[8,6]<-s.mean[3,1]
brkpts[6,6]<-s.mean[5,1]
brkpts[3,6]<-s.mean[8,1]
brkpts[4,6]<-s.mean[7,1]
brkpts[5,6]<-s.mean[6,1]
brkpts[1,6]<-s.mean[2,1]
brkpts[7,6]<-s.mean[4,1]
#q.mean
brkpts[1,7]<-q[6,2]
brkpts[2,7]<-q[7,2]
brkpts[3,7]<-q[1,2]
brkpts[4,7]<-q[2,2]
brkpts[5,7]<-q[3,2]
brkpts[6,7]<-q[4,2]
brkpts[7,7]<-q[5,2]
brkpts[8,7]<-quantile(s.gcsk$WTMP,0.75,type=1)
#t.mean
brkpts[1,8]<-q[6,3]
brkpts[2,8]<-q[7,3]
brkpts[3,8]<-q[1,3]
brkpts[4,8]<-q[2,3]
brkpts[5,8]<-q[3,3]
brkpts[6,8]<-q[4,3]
brkpts[7,8]<-q[5,3]
brkpts[8,8]<-quantile(s.gcsk$WTMP,0.9,type=1)
#max
brkpts[1,13]<-q[6,4]
brkpts[2,13]<-q[7,4]
brkpts[3,13]<-q[1,4]
brkpts[4,13]<-q[2,4]
brkpts[5,13]<-q[3,4]
brkpts[6,13]<-q[4,4]
brkpts[7,13]<-q[5,4]
brkpts[8,13]<-q[9,4]

#seasonlength10
brkpts[1,14]<-q[6,7]
brkpts[2,14]<-q[7,7]
brkpts[3,14]<-q[1,7]
brkpts[4,14]<-q[2,7]
brkpts[5,14]<-q[3,7]
brkpts[6,14]<-q[4,7]
brkpts[7,14]<-q[5,7]
brkpts[8,14]<-q[9,7]

#seasonlength16
brkpts[1,15]<-q[6,8]
brkpts[2,15]<-q[7,8]
brkpts[3,15]<-q[1,8]
brkpts[4,15]<-q[2,8]
brkpts[5,15]<-q[3,8]
brkpts[6,15]<-q[4,8]
brkpts[7,15]<-q[5,8]
brkpts[8,15]<-q[9,8]



brkpts$oce<-ifelse(brkpts$pop=="Beaufort","a",ifelse(brkpts$pop=="Folly Beach","a",ifelse(brkpts$pop=="Great Bay","a",ifelse(brkpts$pop=="Humboldt","p",ifelse(brkpts$pop=="Oyster","a",ifelse(brkpts$pop=="Tomales","p",ifelse(brkpts$pop=="Woods Hole","a",ifelse(brkpts$pop=="Willapa","p",ifelse(brkpts$pop=="Skidaway","a",NA)))))))))


```
### Breakpoint Y, maximal trait performance 

```{r,echo=F,warning=F}
mods.brk<-list(
   "nullo"=glm(brkpty~1,brkpts,family="gaussian"),
  "lato"=glm(brkpty~lat+oce,brkpts,family="gaussian"),
  "meano"=glm(brkpty~mean+oce,brkpts,family="gaussian"),
  "s.meano"=glm(brkpty~s.mean+oce,brkpts,family="gaussian"),
  "q.meano"=glm(brkpty~q.mean+oce,brkpts,family="gaussian"),
  "t.meano"=glm(brkpty~t.mean+oce,brkpts,family="gaussian"),
  "seasonlengtho10"=glm(brkpty~seasonlength10+oce,brkpts,family="gaussian"),
  "seasonlengtho16"=glm(brkpty~seasonlength16+oce,brkpts,family="gaussian"),
  "maxo"=glm(brkpty~max+oce,brkpts,family="gaussian"),
  "lat"=glm(brkpty~lat,brkpts,family="gaussian"),
  "mean"=glm(brkpty~mean,brkpts,family="gaussian"),
  "s.mean"=glm(brkpty~s.mean,brkpts,family="gaussian"),
  "q.mean"=glm(brkpty~q.mean,brkpts,family="gaussian"),
  "t.mean"=glm(brkpty~t.mean,brkpts,family="gaussian"),
  "seasonlength10"=glm(brkpty~seasonlength10,brkpts,family="gaussian"),
  "seasonlength16"=glm(brkpty~seasonlength16,brkpts,family="gaussian"),
  "omax"=glm(brkpty~max,brkpts,family="gaussian"),
  "o*lat"=glm(brkpty~lat*oce,brkpts,family="gaussian"),
  "o*mean"=glm(brkpty~mean*oce,brkpts,family="gaussian"),
  "o*s.mean"=glm(brkpty~s.mean*oce,brkpts,family="gaussian"),
  "o*q.mean"=glm(brkpty~q.mean*oce,brkpts,family="gaussian"),
  "o*t.mean"=glm(brkpty~t.mean*oce,brkpts,family="gaussian"),
  "o*seasonlength10"=glm(brkpty~seasonlength10*oce,brkpts,family="gaussian"),
  "seasonlength16"=glm(brkpty~seasonlength16*oce,brkpts,family="gaussian"),
  "o*max"=glm(brkpty~max*oce,brkpts,family="gaussian")
  )

  

aictab(mods.brk)

summary(lm(brkpty~seasonlength10,brkpts))


brkpts$oce<-as.factor(brkpts$oce)

ggplot(brkpts,aes(x=seasonlength10,y=brkpty))+
  geom_point(size=3,aes(color=oce))+theme_classic()+
  ylab("Maximal Trait Performance (g)")+
  xlab("Season Length (days), 10C")+
  theme(text=element_text(family="arial",size=22))+
  scale_color_manual(labels=c("Atlantic","Pacific"),name="Ocean", values=c('red','blue'))+
  scale_fill_manual(labels=c("Atlantic","Pacific"),name="Ocean", values=c('red','blue'))+geom_smooth(method="lm",se=F,color="black")+theme(text=element_text(family="arial",size=22))


```

Once again the null model wins out, but when we go with the next best supported model (seasonlength10) we get a well supported, signficant relationship of increasing growth with increasing season length 

### Breakpoint X, thermal optima

```{r,echo=F,warning=F}
mods.brkx<-list(
   "nullo"=glm(brkptx~1,brkpts,family="gaussian"),
  "lato"=glm(brkptx~lat+oce,brkpts,family="gaussian"),
  "meano"=glm(brkptx~mean+oce,brkpts,family="gaussian"),
  "s.meano"=glm(brkptx~s.mean+oce,brkpts,family="gaussian"),
  "q.meano"=glm(brkptx~q.mean+oce,brkpts,family="gaussian"),
  "t.meano"=glm(brkptx~t.mean+oce,brkpts,family="gaussian"),
  "seasonlengtho10"=glm(brkptx~seasonlength10+oce,brkpts,family="gaussian"),
  "seasonlengtho16"=glm(brkptx~seasonlength16+oce,brkpts,family="gaussian"),
  "maxo"=glm(brkptx~max+oce,brkpts,family="gaussian"),
  "lat"=glm(brkptx~lat,brkpts,family="gaussian"),
  "mean"=glm(brkptx~mean,brkpts,family="gaussian"),
  "s.mean"=glm(brkptx~s.mean,brkpts,family="gaussian"),
  "q.mean"=glm(brkptx~q.mean,brkpts,family="gaussian"),
  "t.mean"=glm(brkptx~t.mean,brkpts,family="gaussian"),
  "seasonlength10"=glm(brkptx~seasonlength10,brkpts,family="gaussian"),
  "seasonlength16"=glm(brkptx~seasonlength16,brkpts,family="gaussian"),
  "omax"=glm(brkptx~max,brkpts,family="gaussian"),
  "o*lat"=glm(brkptx~lat*oce,brkpts,family="gaussian"),
  "o*mean"=glm(brkptx~mean*oce,brkpts,family="gaussian"),
  "o*s.mean"=glm(brkptx~s.mean*oce,brkpts,family="gaussian"),
  "o*q.mean"=glm(brkptx~q.mean*oce,brkpts,family="gaussian"),
  "o*t.mean"=glm(brkptx~t.mean*oce,brkpts,family="gaussian"),
  "o*seasonlength10"=glm(brkptx~seasonlength10*oce,brkpts,family="gaussian"),
  "seasonlength16"=glm(brkptx~seasonlength16*oce,brkpts,family="gaussian"),
  "o*max"=glm(brkptx~max*oce,brkpts,family="gaussian")
  )
  
aictab(mods.brkx)

summary(lm(brkptx~seasonlength10,brkpts))

ggplot(brkpts,aes(x=seasonlength10,y=brkptx))+
  geom_point(size=3,aes(color=oce))+theme_classic()+
  ylab("Thermal Optima")+
  xlab("Season Length (days), 10C")+
  theme(text=element_text(family="arial",size=22))+
  scale_color_manual(labels=c("Atlantic","Pacific"),name="Ocean", values=c('red','blue'))+
  scale_fill_manual(labels=c("Atlantic","Pacific"),name="Ocean", values=c('red','blue'))+geom_smooth(color="black",method="lm",se=F)+theme(text=element_text(family="arial",size=22))

```

X optima results are not  signficant, although we still see a pattern of general increase with habitat temperature. This is more or less the result we found from x optima of length.  


## Quadratic

One reason we are checking quadratic is that sometimes the optima isn't the optima! If you closely examine the segmented regressions, you see that in some cases the second segment's slope does not appear to be negative. Instead, it plateaus. This raises the question whether we can really define our breakpoint as optima. Potentially, we could interpret the breakpoints as the lowest temperature of maximum weight At any rate, one idea is to redo all the analysis we just did for segmented regression but with a quadratic model, and seeing if we get a similar result in both the stacking but also the trends of the maximal weight and optima as we did with the segmented regression. 

```{r,echo=F,warning=F}
#some quick data exploration
quadm<-(glm(wt~poly(growth$temp,2)+pop,growth,family="gaussian"))
hist(resid(quadm))
plot(quadm)

growth$quad<-poly(growth$temp,2)
bf<-filter(growth,pop=="Beaufort")
fb<-filter(growth,pop=="Folly Beach")
gb<-filter(growth,pop=="Great Bay")
hm<-filter(growth,pop=="Humboldt")
oy<-filter(growth,pop=="Oyster")
sk<-filter(growth,pop=="Skidaway")
wp<-filter(growth,pop=="Willapa")
wh<-filter(growth,pop=="Woods Hole")

xminq<-min(poly(growth$temp,2),na.rm=T)
xmaxq<-max(poly(growth$temp,2),na.rm=T)

qmgb<-(lm(wt~poly(gb$temp,2,raw=T),gb))
cfgb<-coef(qmgb)
brkpts[3,11]<-(-cfgb[2]/(2*(cfgb[3])))
brkpts[3,12]<-cfgb[1]+cfgb[2]*brkpts[3,11]+cfgb[3]*(brkpts[3,11]^2)

qmwh<-(lm(wt~poly(wh$temp,2,raw=T),wh))
cfwh<-coef(qmwh)
brkpts[4,11]<-(-cfwh[2]/(2*(cfwh[3])))
brkpts[4,12]<-cfwh[1]+cfwh[2]*brkpts[4,11]+cfwh[3]*(brkpts[4,11]^2)

qmoy<-(lm(wt~poly(oy$temp,2,raw=T),oy))
cfoy<-coef(qmoy)
brkpts[5,11]<-(-cfoy[2]/(2*(cfoy[3])))
brkpts[5,12]<-cfoy[1]+cfoy[2]*brkpts[5,11]+cfoy[3]*(brkpts[5,11]^2)

qmbf<-(lm(wt~poly(bf$temp,2,raw=T),bf))
cfbf<-coef(qmbf)
brkpts[6,11]<-(-cfbf[2]/(2*(cfbf[3])))
brkpts[6,12]<-cfbf[1]+cfbf[2]*brkpts[6,11]+cfbf[3]*(brkpts[6,11]^2)


qmfb<-(lm(wt~poly(fb$temp,2,raw=T),fb))
cffb<-coef(qmfb)
brkpts[7,11]<-(-cffb[2]/(2*(cffb[3])))
brkpts[7,12]<-cffb[1]+cffb[2]*brkpts[7,11]+cffb[3]*(brkpts[7,11]^2)

qmsk<-(lm(wt~poly(sk$temp,2,raw=T),sk))
cfsk<-coef(qmsk)
brkpts[8,11]<-(-cfsk[2]/(2*(cfsk[3])))
brkpts[8,12]<-cfsk[1]+cfsk[2]*brkpts[8,11]+cfsk[3]*(brkpts[8,11]^2)

qmwp<-(lm(wt~poly(wp$temp,2,raw=T),wp))
cfwp<-coef(qmwp)
brkpts[1,11]<-(-cfwp[2]/(2*(cfwp[3])))
brkpts[1,12]<-cfwp[1]+cfwp[2]*brkpts[1,11]+cfwp[3]*(brkpts[1,11]^2)

qmhm<-(lm(wt~poly(hm$temp,2,raw=T),hm))
cfhm<-coef(qmhm)
brkpts[2,11]<-(-cfhm[2]/(2*(cfhm[3])))
brkpts[2,12]<-cfhm[1]+cfhm[2]*brkpts[2,11]+cfhm[3]*(brkpts[2,11]^2)


growth$population<-factor(growth$pop,levels=c("Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"))


ggplot(growth,aes(y=wt,x=temp,group=population,linetype=population))+geom_smooth(method='lm',formula=y~poly(x,2),se=F,aes(color=population,size=population))+geom_point()+facet_wrap(population~.)+
  theme_classic()+theme(legend.position = "none")+labs(y="Weight (g)",x="Temperature (°C)")+scale_y_continuous(breaks=c(0.005,0.01,0.015,0.02,0.025))+scale_x_continuous(breaks=c(16,20,24,26,28,30))+
  scale_color_manual(values=c("dark violet","navy","forest green","gold","dark orange","tomato","dark violet","navy"),labels=c("Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"),name="population")+
  scale_linetype_manual(values=c(1,1,1,1,1,1,3,3),labels=c("Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"),name="population")+
  scale_size_manual(values=c(1.2,1.2,1.2,1.2,1.2,1.2,1.2,1.2),labels=c("Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"),name="Population")+theme(text=element_text(family="arial",size=22))

ggplot(growth,aes(y=wt,x=temp,group=population,color=population,linetype=population))+geom_smooth(method='lm',formula=y~poly(x,2),se=F,aes(color=population,size=population))+
  scale_y_continuous(breaks=c(0.005,0.01,0.015,0.02,0.025))+scale_x_continuous(breaks=c(16,20,24,26,28,30))+
  scale_color_manual(values=c("dark violet","navy","forest green","gold","dark orange","tomato","dark violet","navy"),labels=c("Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"),name="Population")+
  scale_linetype_manual(values=c(1,1,1,1,1,1,3,3),labels=c("Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"),name="Population")+
  scale_size_manual(values=c(1.2,1.2,1.2,1.2,1.2,1.2,1.2,1.2),labels=c("Great Bay","Woods Hole","Oyster","Beaufort","Folly Beach","Skidaway","Willapa","Humboldt"),name="Population")+
  theme_classic()+labs(y="Weight (g)",x="Temperature (°C)")+theme(text=element_text(family="arial",size=22))

```

Here, we see that our regressions are more or less stacked with cold populations on top. This is indicative of countergradient variation. 

## X  Breakpoint, thermal optima, Quadratic

```{r,echo=F,warning=F}
mods.brkyq<-list(
 "nullo"=glm(brkptyq~1,brkpts,family="gaussian"),
  "lato"=glm(brkptyq~lat+oce,brkpts,family="gaussian"),
  "meano"=glm(brkptyq~mean+oce,brkpts,family="gaussian"),
  "s.meano"=glm(brkptyq~s.mean+oce,brkpts,family="gaussian"),
  "q.meano"=glm(brkptyq~q.mean+oce,brkpts,family="gaussian"),
  "t.meano"=glm(brkptyq~t.mean+oce,brkpts,family="gaussian"),
  "seasonlengtho10"=glm(brkptyq~seasonlength10+oce,brkpts,family="gaussian"),
  "seasonlengtho16"=glm(brkptyq~seasonlength16+oce,brkpts,family="gaussian"),
  "maxo"=glm(brkptyq~max+oce,brkpts,family="gaussian"),
  "lat"=glm(brkptyq~lat,brkpts,family="gaussian"),
  "mean"=glm(brkptyq~mean,brkpts,family="gaussian"),
  "s.mean"=glm(brkptyq~s.mean,brkpts,family="gaussian"),
  "q.mean"=glm(brkptyq~q.mean,brkpts,family="gaussian"),
  "t.mean"=glm(brkptyq~t.mean,brkpts,family="gaussian"),
  "seasonlength10"=glm(brkptyq~seasonlength10,brkpts,family="gaussian"),
  "seasonlength16"=glm(brkptyq~seasonlength16,brkpts,family="gaussian"),
  "omax"=glm(brkptyq~max,brkpts,family="gaussian"),
  "o*lat"=glm(brkptyq~lat*oce,brkpts,family="gaussian"),
  "o*mean"=glm(brkptyq~mean*oce,brkpts,family="gaussian"),
  "o*s.mean"=glm(brkptyq~s.mean*oce,brkpts,family="gaussian"),
  "o*q.mean"=glm(brkptyq~q.mean*oce,brkpts,family="gaussian"),
  "o*t.mean"=glm(brkptyq~t.mean*oce,brkpts,family="gaussian"),
  "o*seasonlength10"=glm(brkptyq~seasonlength10*oce,brkpts,family="gaussian"),
  "seasonlength16"=glm(brkptyq~seasonlength16*oce,brkpts,family="gaussian"),
  "o*max"=glm(brkptyq~max*oce,brkpts,family="gaussian")
  )

aictab(mods.brkyq)

brkptxmq<-glm(brkptyq~seasonlength10,brkpts,family="gaussian")
summary(brkptxmq)

ggplot(brkpts,aes(x=seasonlength10,y=brkptyq))+
  geom_point(size=3,aes(color=oce))+geom_smooth(color="black",method="lm",se=F)+theme_classic()+
  ylab("Weight (g)")+
  xlab("Length of Season (days) 10c")+
  theme(text=element_text(family="arial",size=22))+
  scale_color_manual(labels=c("Atlantic","Pacific"),name="Ocean", values=c('red','blue'))+
  scale_fill_manual(labels=c("Atlantic","Pacific"),name="Ocean", values=c('red','blue'))
```

This is clearly not a signficant reaction. The thermal optimas given by quadratics are absurdly high. We should put more trust (but not a lot more) in those produced by segmented regression.

### Y Breakpoints, maximal trait performance, Quadratic

```{r,echo=F,warning=F}
mods.brkxq<-list(
   "nullo"=glm(brkptxq~1,brkpts,family="gaussian"),
  "lato"=glm(brkptxq~lat+oce,brkpts,family="gaussian"),
  "meano"=glm(brkptxq~mean+oce,brkpts,family="gaussian"),
  "s.meano"=glm(brkptxq~s.mean+oce,brkpts,family="gaussian"),
  "q.meano"=glm(brkptxq~q.mean+oce,brkpts,family="gaussian"),
  "t.meano"=glm(brkptxq~t.mean+oce,brkpts,family="gaussian"),
  "seasonlengtho10"=glm(brkptxq~seasonlength10+oce,brkpts,family="gaussian"),
  "seasonlengtho16"=glm(brkptxq~seasonlength16+oce,brkpts,family="gaussian"),
  "maxo"=glm(brkptxq~max+oce,brkpts,family="gaussian"),
  "lat"=glm(brkptxq~lat,brkpts,family="gaussian"),
  "mean"=glm(brkptxq~mean,brkpts,family="gaussian"),
  "s.mean"=glm(brkptxq~s.mean,brkpts,family="gaussian"),
  "q.mean"=glm(brkptxq~q.mean,brkpts,family="gaussian"),
  "t.mean"=glm(brkptxq~t.mean,brkpts,family="gaussian"),
  "seasonlength10"=glm(brkptxq~seasonlength10,brkpts,family="gaussian"),
  "seasonlength16"=glm(brkptxq~seasonlength16,brkpts,family="gaussian"),
  "omax"=glm(brkptxq~max,brkpts,family="gaussian"),
  "o*lat"=glm(brkptxq~lat*oce,brkpts,family="gaussian"),
  "o*mean"=glm(brkptxq~mean*oce,brkpts,family="gaussian"),
  "o*s.mean"=glm(brkptxq~s.mean*oce,brkpts,family="gaussian"),
  "o*q.mean"=glm(brkptxq~q.mean*oce,brkpts,family="gaussian"),
  "o*t.mean"=glm(brkptxq~t.mean*oce,brkpts,family="gaussian"),
  "o*seasonlength10"=glm(brkptxq~seasonlength10*oce,brkpts,family="gaussian"),
  "seasonlength16"=glm(brkptxq~seasonlength16*oce,brkpts,family="gaussian"),
  "o*max"=glm(brkptxq~max*oce,brkpts,family="gaussian")
  )

aictab(mods.brkxq)

brkptxmq<-glm(brkptxq~max+oce,brkpts,family="gaussian")
summary(brkptxmq)

ggplot(brkpts,aes(x=max,y=brkptxq),group=interaction(oce))+
  geom_point(size=3,aes(color=oce))+geom_smooth(color="black",method="lm",se=F)+theme_classic()+
  ylab("Thermal Optima")+
  xlab("Maximum habitat Temperature (degrees)")+
  theme(text=element_text(family="arial",size=22))+
  scale_color_manual(labels=c("Atlantic","Pacific"),name="Ocean", values=c('red','blue'))+
  scale_fill_manual(labels=c("Atlantic","Pacific"),name="Ocean", values=c('red','blue'))


```

Here, we see a similar trend of increasing weight with latitude as we saw in segmented regression and with any caliper length regression. One outlier of Woods Hole exists, similar to what we saw in growth rate with length. Upon removing this one site, we see a significant relationship. This evidence, taken together with that of the segmented regression and both the quadratic and segmented regressions for caliper length, point to a pattern of countergradient variation in growth. 

```{r,echo=F,warning=F}
brkptsq_wh<-filter(brkpts,pop!="Woods Hole")

mods.brkxq_wh<-list(
   "nullo"=glm(brkptxq~1,brkptsq_wh,family="gaussian"),
  "lato"=glm(brkptxq~lat+oce,brkptsq_wh,family="gaussian"),
  "meano"=glm(brkptxq~mean+oce,brkptsq_wh,family="gaussian"),
  "s.meano"=glm(brkptxq~s.mean+oce,brkptsq_wh,family="gaussian"),
  "q.meano"=glm(brkptxq~q.mean+oce,brkptsq_wh,family="gaussian"),
  "t.meano"=glm(brkptxq~t.mean+oce,brkptsq_wh,family="gaussian"),
  "seasonlengtho10"=glm(brkptxq~seasonlength10+oce,brkptsq_wh,family="gaussian"),
  "seasonlengtho16"=glm(brkptxq~seasonlength16+oce,brkptsq_wh,family="gaussian"),
  "maxo"=glm(brkptxq~max+oce,brkptsq_wh,family="gaussian"),
  "lat"=glm(brkptxq~lat,brkptsq_wh,family="gaussian"),
  "mean"=glm(brkptxq~mean,brkptsq_wh,family="gaussian"),
  "s.mean"=glm(brkptxq~s.mean,brkptsq_wh,family="gaussian"),
  "q.mean"=glm(brkptxq~q.mean,brkptsq_wh,family="gaussian"),
  "t.mean"=glm(brkptxq~t.mean,brkptsq_wh,family="gaussian"),
  "seasonlength10"=glm(brkptxq~seasonlength10,brkptsq_wh,family="gaussian"),
  "seasonlength16"=glm(brkptxq~seasonlength16,brkptsq_wh,family="gaussian"),
  "omax"=glm(brkptxq~max,brkptsq_wh,family="gaussian"),
  "o*lat"=glm(brkptxq~lat*oce,brkptsq_wh,family="gaussian"),
  "o*mean"=glm(brkptxq~mean*oce,brkptsq_wh,family="gaussian"),
  "o*s.mean"=glm(brkptxq~s.mean*oce,brkptsq_wh,family="gaussian"),
  "o*q.mean"=glm(brkptxq~q.mean*oce,brkptsq_wh,family="gaussian"),
  "o*t.mean"=glm(brkptxq~t.mean*oce,brkptsq_wh,family="gaussian"),
  "o*seasonlength10"=glm(brkptxq~seasonlength10*oce,brkptsq_wh,family="gaussian"),
  "seasonlength16"=glm(brkptxq~seasonlength16*oce,brkptsq_wh,family="gaussian"),
  "o*max"=glm(brkptxq~max*oce,brkptsq_wh,family="gaussian")
  )

aictab(mods.brkxq_wh)


brkptxqm_wh<-lm(brkptxq~seasonlength10,brkptsq_wh)
summary(brkptxqm_wh)

ggplot(brkptsq_wh,aes(x=seasonlength10,y=brkptxq))+
  geom_point(size=3,aes(color=oce))+geom_smooth(color="black",method="lm",se=F)+theme_classic()+
  ylab("Thermal Optima")+
  xlab("Season length (10, days)")+
  theme(text=element_text(family="arial",size=22))+
  scale_color_manual(labels=c("Atlantic","Pacific"),name="Ocean", values=c('red','blue'))+
  scale_fill_manual(labels=c("Atlantic","Pacific"),name="Ocean", values=c('red','blue'))

```
Here, we see that the maxima growth rate pattern is more or less preserved. While we don't trust the quadratic estimates for the optima, I do trust that there is a pattern of increasing growth rate with higher latitude. This is evidence for countergradient variation in growth. We can confirm this by looking further at growth in weight as well as in consumption rate. 

Finally, let us compare the breakpoints we have extracted from segmented and quadratic regression. We want to know if we see significantly different results in methods, because if we do then we have to be careful about which once we select (seg v. quad). We see here that while thermal optima estimates differ significantly between quad and seg, they do not when estimating maximal trait performance. Importantly, the sign of both relationships is the same. Therefore, we can be confident that our conclusion of countergradient variation in maximal trait performance is correct.
```{r,echo=F}
brkptnewx<-gather(brkpts, modeltypex, x, c(brkptx,brkptxq)) 
brkptnewy<-gather(brkpts,modeltypey,y,c(brkpty,brkptyq))

ggplot(brkptnewx,aes(x=seasonlength10,y=x,group=modeltypex,color=modeltypex))+geom_point()+theme_classic()+scale_color_manual(labels=c("Segmented","Quadratic"),name="Thermal Optima",values=c("red","blue"))+geom_smooth(method=lm,se=F)

ggplot(brkptnewy,aes(x=seasonlength10,y=y,group=modeltypey,color=modeltypey))+geom_point()+theme_classic()+scale_color_manual(labels=c("Segmented","Quadratic"),name="Maximal Trait Performance",values=c("red","blue"))+geom_smooth(method=lm,se=F)

brkptnewx$pop<-as.character(brkptnewx$pop)
summary(lm(x~modeltypex,brkptnewx))

brkptnewy$pop<-as.character(brkptnewy$pop)
summary(lm(y~modeltypey,brkptnewy))
```



```{r,include=F}
#brkpts$pop<-unlist(brkpts$pop)
#write.csv(brkpts,"C:/Users/drewv/Documents/UMASS/data/growth_wt.csv",row.names=F)

```